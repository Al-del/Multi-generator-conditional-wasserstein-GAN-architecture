{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:10:52.658533Z",
     "start_time": "2024-08-30T14:10:52.655668Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from asyncio import sleep\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "from networkx.readwrite.graph6 import n_to_data\n",
    "from sympy import transpose\n",
    "\n",
    "from shallow_nn_model_class import shallow_nn_models\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:10:53.882646Z",
     "start_time": "2024-08-30T14:10:53.869913Z"
    }
   },
   "source": [
    "df=pd.read_csv('BCI Tests - Foaie1.csv')\n",
    "#Get df[\"Name\"] as title\n",
    "df[\"Nume\"]=df[\"Nume\"].apply(lambda x: x.title())\n",
    "df.columns=df.columns.str.strip()\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Nume  Culoare Raspuns Intrebari\n",
       "0      David        2               3/5\n",
       "1     Amalia        3               2/5\n",
       "2     Robert        2              5/5 \n",
       "3     Darius        0               5/5\n",
       "4     Andrei        3               5/5\n",
       "5       Toni        1               3/5\n",
       "6     Asalos        2               4/5\n",
       "7     Bogdan        1               4/5\n",
       "8     Toni 2        1               5/5\n",
       "9   Darius 2        0               5/5\n",
       "10     Matei        1               4/5\n",
       "11  Amalia 2        3               3/5\n",
       "12  Andrei 2        3               5/5\n",
       "13       Edi        2               5/5\n",
       "14      Tina        0               2/5\n",
       "15    Tina 2        0               5/5\n",
       "16  Robert 2        2               5/5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nume</th>\n",
       "      <th>Culoare</th>\n",
       "      <th>Raspuns Intrebari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>2</td>\n",
       "      <td>3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amalia</td>\n",
       "      <td>3</td>\n",
       "      <td>2/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>2</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Darius</td>\n",
       "      <td>0</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrei</td>\n",
       "      <td>3</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toni</td>\n",
       "      <td>1</td>\n",
       "      <td>3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asalos</td>\n",
       "      <td>2</td>\n",
       "      <td>4/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bogdan</td>\n",
       "      <td>1</td>\n",
       "      <td>4/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toni 2</td>\n",
       "      <td>1</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darius 2</td>\n",
       "      <td>0</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Matei</td>\n",
       "      <td>1</td>\n",
       "      <td>4/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amalia 2</td>\n",
       "      <td>3</td>\n",
       "      <td>3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Andrei 2</td>\n",
       "      <td>3</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Edi</td>\n",
       "      <td>2</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tina</td>\n",
       "      <td>0</td>\n",
       "      <td>2/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tina 2</td>\n",
       "      <td>0</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Robert 2</td>\n",
       "      <td>2</td>\n",
       "      <td>5/5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:10:55.036386Z",
     "start_time": "2024-08-30T14:10:55.022608Z"
    }
   },
   "source": [
    "from Preprocces import  pipeline\n",
    "def preprocessing(path):\n",
    "    notched=[50, 100]\n",
    "    ica=ICA(n_components=16,\n",
    "            max_iter='auto',           \n",
    "            method='fastica',\n",
    "            random_state=42)\n",
    "    Pipeline=pipeline(ica)\n",
    "    raw=Pipeline.load_Data(path)\n",
    "    print(raw)\n",
    "    print(raw.info['ch_names'])\n",
    "    raw.pick_channels(['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7'])\n",
    "    high_passed=raw.filter(l_freq=1.0, h_freq=None)\n",
    "    high_passed=high_passed.filter(l_freq=None, h_freq=100.0)\n",
    "    notched=high_passed.notch_filter(notched,\n",
    "                                     picks='eeg',\n",
    "                                     filter_length='auto',\n",
    "                                     phase='zero',\n",
    "                                     verbose=True)\n",
    "    notched=notched.set_eeg_reference('average')\n",
    "    ica=ICA(n_components=None,\n",
    "            max_iter='auto',\n",
    "            method='fastica',\n",
    "            random_state=97)\n",
    "    ica.fit(notched)\n",
    "    raw.load_data()\n",
    "    ic_labels=label_components(notched, ica, method='iclabel')\n",
    "    print(ic_labels['labels'])\n",
    "    labels=ic_labels['labels']\n",
    "    exclude_idx=[idx for idx, label in enumerate(labels) if label not in ['brain']]\n",
    "    print(f'Excluding these ICA components{exclude_idx}')\n",
    "    reconst_raw=notched.copy()\n",
    "    ica.apply(reconst_raw, exclude=exclude_idx) \n",
    "    #spectrumus=reconst_raw.compute_psd()\n",
    "    #spectrumus.plot(exclude='bads', amplitude=False).savefig('plangus.png')\n",
    "    return reconst_raw"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:10:55.662647Z",
     "start_time": "2024-08-30T14:10:55.657140Z"
    }
   },
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "def load_data_by_color(id, df):\n",
    "    X = []\n",
    "    y = []\n",
    "    df = df[df[\"Culoare\"] == id]\n",
    "    path = './Recordings'\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        nume = df.iloc[i]['Nume']\n",
    "        path_to_file = os.path.join(path, nume)\n",
    "        \n",
    "        if os.path.exists(path_to_file):\n",
    "            print(f'File {nume} loaded')\n",
    "            files_in_folder = os.listdir(path_to_file)\n",
    "            \n",
    "            for file in files_in_folder:\n",
    "                if 'Vid Attention' in file or 'vid attention' in file:\n",
    "                    path_to_file_attention = os.path.join(path_to_file, file)\n",
    "                    print(f\"Atentie {path_to_file_attention}\")\n",
    "                    preprocessed_x = preprocessing(path_to_file_attention)\n",
    "                    epochs = create_epochs(preprocessed_x)\n",
    "                    X.append(epochs)\n",
    "                    y.extend([1] * epochs.shape[0])\n",
    "                \n",
    "                if 'non-attention' in file or 'Non-Attention' in file or 'no attention' in file:\n",
    "                    path_to_file_non_attention = os.path.join(path_to_file, file)\n",
    "                    print(f\"Non-Atentie {path_to_file_non_attention}\")\n",
    "                    preprocessed_x = preprocessing(path_to_file_non_attention)\n",
    "                    epochs = create_epochs(preprocessed_x)\n",
    "                    X.append(epochs)\n",
    "                    y.extend([0] * epochs.shape[0])\n",
    "        else:\n",
    "            print(f'File {nume} not found')\n",
    "    \n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_epochs(raw_data):\n",
    "    tmin = 0.0\n",
    "    sfreq = raw_data.info['sfreq']\n",
    "    tmax = (1000 - 1) / sfreq  # Calculate tmax to get 1000 samples\n",
    "\n",
    "    events = mne.make_fixed_length_events(raw_data, start=0, stop=None, duration=tmax + 1/sfreq)\n",
    "    epochs = mne.Epochs(raw_data, events, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "    # Ensure the epochs have the shape (n, 16, 1000)\n",
    "    epochs_data = epochs.get_data()\n",
    "    if epochs_data.shape[2] != 1000:\n",
    "        raise ValueError(f\"Epochs do not have the required 1000 samples, but {epochs_data.shape[2]}\")\n",
    "\n",
    "    # Reshape the epochs data to (n_samples, seq_len, feature_dim)\n",
    "    n_epochs, n_channels, n_samples = epochs_data.shape\n",
    "    if n_samples != 1000:\n",
    "        raise ValueError(f\"Expected 1000 samples, but got {n_samples}\")\n",
    "\n",
    "    # Reshape to (n_samples, seq_len, feature_dim)\n",
    "    reshaped_data = epochs_data.reshape(n_epochs , n_channels, 1000)\n",
    "\n",
    "    return reshaped_data"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:11:08.482589Z",
     "start_time": "2024-08-30T14:10:56.496161Z"
    }
   },
   "cell_type": "code",
   "source": "X_Blue, y_Blue =load_data_by_color(0, df)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Darius loaded\n",
      "Non-Atentie ./Recordings/Darius/subj-1_ses-S001_task-Darius Vid Non-Attention_run-001_20240816_114717_eeg_f495e7c2-d7ce-406b-8d23-2b42367413b9-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Darius Vid Non-Attention_run-001_20240816_114717_eeg_f495e7c2-d7ce-406b-8d23-2b42367413b9-raw.fif, 21 x 83675 (334.7 s), ~13.4 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[2, 9]\n",
      "File Darius 2 loaded\n",
      "Atentie ./Recordings/Darius 2/subj-1_ses-S001_task-Darius 2 vid attention_run-001_20240816_134409_eeg_7f0c8f6e-8e30-4c1c-a9ad-f0c4dd9d54f3-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Darius 2 vid attention_run-001_20240816_134409_eeg_7f0c8f6e-8e30-4c1c-a9ad-f0c4dd9d54f3-raw.fif, 21 x 82600 (330.4 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'brain', 'eye blink', 'brain', 'other', 'brain', 'brain', 'other', 'brain', 'other', 'other', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[3, 5, 8, 10, 11]\n",
      "Non-Atentie ./Recordings/Darius 2/subj-1_ses-S001_task-Darius 2 vid no attention_run-001_20240816_135026_eeg_7f0c8f6e-8e30-4c1c-a9ad-f0c4dd9d54f3-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Darius 2 vid no attention_run-001_20240816_135026_eeg_7f0c8f6e-8e30-4c1c-a9ad-f0c4dd9d54f3-raw.fif, 21 x 83325 (333.3 s), ~13.4 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'brain', 'eye blink', 'brain', 'brain', 'other', 'brain', 'other', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[3, 6, 8]\n",
      "File Tina loaded\n",
      "Non-Atentie ./Recordings/Tina/subj-1_ses-S002_task-Tina vid non-attention_run-001_20240820_145407_eeg_772523e6-4d3c-478f-bebc-4a601b91f857-raw.fif\n",
      "<Raw | subj-1_ses-S002_task-Tina vid non-attention_run-001_20240820_145407_eeg_772523e6-4d3c-478f-bebc-4a601b91f857-raw.fif, 21 x 82850 (331.4 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'brain', 'other', 'other', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[1, 7, 8]\n",
      "File Tina 2 loaded\n",
      "Non-Atentie ./Recordings/Tina 2/subj-1_ses-S002_task-Tina2 vid non-attention_run-001_20240820_151548_eeg_772523e6-4d3c-478f-bebc-4a601b91f857-raw.fif\n",
      "<Raw | subj-1_ses-S002_task-Tina2 vid non-attention_run-001_20240820_151548_eeg_772523e6-4d3c-478f-bebc-4a601b91f857-raw.fif, 21 x 82600 (330.4 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'eye blink', 'eye blink', 'brain', 'other', 'brain', 'brain', 'brain', 'eye blink', 'eye blink', 'brain', 'other', 'brain', 'brain']\n",
      "Excluding these ICA components[2, 3, 5, 9, 10, 12]\n",
      "Atentie ./Recordings/Tina 2/subj-1_ses-S002_task-Tina2 vid attention_run-001_20240820_150735_eeg_772523e6-4d3c-478f-bebc-4a601b91f857-raw.fif\n",
      "<Raw | subj-1_ses-S002_task-Tina2 vid attention_run-001_20240820_150735_eeg_772523e6-4d3c-478f-bebc-4a601b91f857-raw.fif, 21 x 82550 (330.2 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'other', 'brain', 'other', 'brain', 'other', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[2, 7, 9, 11]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:02:45.025691Z",
     "start_time": "2024-08-30T08:02:45.021798Z"
    }
   },
   "cell_type": "code",
   "source": "X_Blue.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 16, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:00.242652Z",
     "start_time": "2024-08-30T08:02:45.112947Z"
    }
   },
   "cell_type": "code",
   "source": "X_Galben, y_Galben = load_data_by_color(1, df)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Toni loaded\n",
      "Atentie ./Recordings/Toni/subj-1_ses-S001_task-Toni vid attention_run-001_20240817_143450_eeg_311aeea8-357d-44a7-8083-83a9fd9e5d26-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Toni vid attention_run-001_20240817_143450_eeg_311aeea8-357d-44a7-8083-83a9fd9e5d26-raw.fif, 21 x 83125 (332.5 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'brain', 'brain', 'eye blink', 'other', 'brain', 'brain', 'brain', 'other', 'other', 'other', 'brain', 'other', 'brain']\n",
      "Excluding these ICA components[4, 5, 9, 10, 11, 13]\n",
      "File Bogdan loaded\n",
      "Non-Atentie ./Recordings/Bogdan/subj-2_ses-S001_task-Bogdan Vid Non-Attention_run-001_20240814_120532_eeg_e7290c53-8945-4dbc-bdbe-5.fif\n",
      "<Raw | subj-2_ses-S001_task-Bogdan Vid Non-Attention_run-001_20240814_120532_eeg_e7290c53-8945-4dbc-bdbe-5.fif, 21 x 84275 (337.1 s), ~13.5 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[4]\n",
      "Atentie ./Recordings/Bogdan/subj-2_ses-S001_task-Bogdan Vid Attention_run-001_20240814_115006_eeg_e7290c53-8945-4dbc-bdbe-533d5.fif\n",
      "<Raw | subj-2_ses-S001_task-Bogdan Vid Attention_run-001_20240814_115006_eeg_e7290c53-8945-4dbc-bdbe-533d5.fif, 21 x 86100 (344.4 s), ~13.8 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye blink', 'brain', 'brain', 'brain', 'brain', 'brain', 'muscle artifact', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 6, 10]\n",
      "File Toni 2 loaded\n",
      "Non-Atentie ./Recordings/Toni 2/subj-1_ses-S001_task-Toni 2 vid non-attention_run-002_20240817_152823_eeg_b145790c-c447-4d69-bf7e-1bf7745465a0-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Toni 2 vid non-attention_run-002_20240817_152823_eeg_b145790c-c447-4d69-bf7e-1bf7745465a0-raw.fif, 21 x 83850 (335.4 s), ~13.5 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye blink', 'other', 'brain', 'brain', 'brain', 'eye blink', 'other', 'other', 'other', 'other', 'brain', 'other', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 1, 5, 6, 7, 8, 9, 11]\n",
      "Atentie ./Recordings/Toni 2/subj-1_ses-S001_task-Toni 2 vid attention_run-002_20240817_151747_eeg_b145790c-c447-4d69-bf7e-1bf7745465a0-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Toni 2 vid attention_run-002_20240817_151747_eeg_b145790c-c447-4d69-bf7e-1bf7745465a0-raw.fif, 21 x 82750 (331.0 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye blink', 'eye blink', 'brain', 'brain', 'other', 'brain', 'other', 'eye blink', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 1, 4, 6, 7, 10]\n",
      "File Matei loaded\n",
      "Atentie ./Recordings/Matei/subj-1_ses-S005_task-Matei vid attention_run-001_20240819_114609_eeg_2d2a04d7-1837-4c63-83b4-0464719e97fa-raw.fif\n",
      "<Raw | subj-1_ses-S005_task-Matei vid attention_run-001_20240819_114609_eeg_2d2a04d7-1837-4c63-83b4-0464719e97fa-raw.fif, 21 x 83150 (332.6 s), ~13.4 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye blink', 'eye blink', 'brain', 'eye blink', 'brain', 'brain', 'other', 'other', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'other']\n",
      "Excluding these ICA components[0, 1, 3, 6, 7, 9, 14]\n",
      "Non-Atentie ./Recordings/Matei/subj-1_ses-S005_task-Matei vid non-attention_run-001_20240819_115448_eeg_2d2a04d7-1837-4c63-83b4-0464719e97fa-raw.fif\n",
      "<Raw | subj-1_ses-S005_task-Matei vid non-attention_run-001_20240819_115448_eeg_2d2a04d7-1837-4c63-83b4-0464719e97fa-raw.fif, 21 x 84200 (336.8 s), ~13.5 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye blink', 'eye blink', 'brain', 'brain', 'brain', 'other', 'other', 'brain', 'other', 'brain', 'brain', 'other', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 1, 5, 6, 8, 11]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:08.852678Z",
     "start_time": "2024-08-30T08:03:00.299383Z"
    }
   },
   "cell_type": "code",
   "source": "X_mov, y_mov = load_data_by_color(2, df)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File David loaded\n",
      "Non-Atentie ./Recordings/David/subj-1_ses-S001_task-David vid non-attention 3_run-001_20240820_122033_eeg_77060f25-2f21-47a9-bb09-1b1bdc69f2f5-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-David vid non-attention 3_run-001_20240820_122033_eeg_77060f25-2f21-47a9-bb09-1b1bdc69f2f5-raw.fif, 21 x 80150 (320.6 s), ~12.9 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'other', 'brain', 'eye blink', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[1, 3, 5, 9]\n",
      "File Robert loaded\n",
      "Non-Atentie ./Recordings/Robert/subj-1_ses-S001_task-Robert Vid Non-Attention_run-001_20240816_145724_eeg_4c57ad90-4ebe-42c0-a094-6b138fb55437-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Robert Vid Non-Attention_run-001_20240816_145724_eeg_4c57ad90-4ebe-42c0-a094-6b138fb55437-raw.fif, 21 x 83090 (332.4 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['muscle artifact', 'brain', 'eye blink', 'brain', 'muscle artifact', 'brain', 'eye blink', 'brain', 'other', 'brain', 'brain', 'brain', 'other', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 2, 4, 6, 8, 12]\n",
      "File Asalos loaded\n",
      "File Edi loaded\n",
      "File Robert 2 loaded\n",
      "Non-Atentie ./Recordings/Robert 2/subj-1_ses-S008_task-Robert 2 vid non-attention_run-001_20240819_142050_eeg_1307967e-ce25-4841-8dda-34df1ceab027-raw.fif\n",
      "<Raw | subj-1_ses-S008_task-Robert 2 vid non-attention_run-001_20240819_142050_eeg_1307967e-ce25-4841-8dda-34df1ceab027-raw.fif, 21 x 82700 (330.8 s), ~13.3 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'eye blink', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[4, 11]\n",
      "Atentie ./Recordings/Robert 2/subj-1_ses-S008_task-Robert 2 vid attention_run-001_20240819_141232_eeg_1307967e-ce25-4841-8dda-34df1ceab027-raw.fif\n",
      "<Raw | subj-1_ses-S008_task-Robert 2 vid attention_run-001_20240819_141232_eeg_1307967e-ce25-4841-8dda-34df1ceab027-raw.fif, 21 x 83250 (333.0 s), ~13.4 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'other', 'brain', 'other', 'brain', 'brain', 'other', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 2, 6, 8, 11]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:21.985256Z",
     "start_time": "2024-08-30T08:03:08.912547Z"
    }
   },
   "cell_type": "code",
   "source": "X_Verde, y_Verde =load_data_by_color(3, df)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Amalia loaded\n",
      "Non-Atentie ./Recordings/Amalia/subj-1_ses-S001_task-Amalia Vid non-attention_run-001_20240816_111920_eeg_f495e7c2-d7ce-406b-8d23-2b42367413b9-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Amalia Vid non-attention_run-001_20240816_111920_eeg_f495e7c2-d7ce-406b-8d23-2b42367413b9-raw.fif, 21 x 84175 (336.7 s), ~13.5 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'brain', 'other', 'brain', 'brain', 'other']\n",
      "Excluding these ICA components[3, 7, 11, 14]\n",
      "Atentie ./Recordings/Amalia/subj-1_ses-S001_task-Amalia Vid Attention_run-001_20240816_110943_eeg_f495e7c2-d7ce-406b-8d23-2b42367413b9-raw.fif\n",
      "<Raw | subj-1_ses-S001_task-Amalia Vid Attention_run-001_20240816_110943_eeg_f495e7c2-d7ce-406b-8d23-2b42367413b9-raw.fif, 21 x 85749 (343.0 s), ~13.8 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other', 'eye blink', 'brain', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'muscle artifact', 'brain', 'other', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 1, 4, 8, 10]\n",
      "File Andrei loaded\n",
      "Non-Atentie ./Recordings/Andrei/subj-1_ses-S003_task-Andrei vid non-attention_run-001_20240820_164224_eeg_03099e9c-5447-47c3-ad06-c2c8da94b24d-raw.fif\n",
      "<Raw | subj-1_ses-S003_task-Andrei vid non-attention_run-001_20240820_164224_eeg_03099e9c-5447-47c3-ad06-c2c8da94b24d-raw.fif, 21 x 83825 (335.3 s), ~13.5 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other', 'brain', 'brain', 'brain', 'other', 'eye blink', 'other', 'brain', 'brain', 'other', 'other', 'brain', 'other', 'brain', 'brain']\n",
      "Excluding these ICA components[0, 4, 5, 6, 9, 10, 12]\n",
      "Atentie ./Recordings/Andrei/subj-1_ses-S001_task-Andrei Vid Attention _run-001_20240814_112342_eeg_e7290c53-8945-4dbc-bdbe-533d.fif\n",
      "<Raw | subj-1_ses-S001_task-Andrei Vid Attention _run-001_20240814_112342_eeg_e7290c53-8945-4dbc-bdbe-533d.fif, 21 x 85575 (342.3 s), ~13.7 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'other', 'other', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'other']\n",
      "Excluding these ICA components[1, 6, 7, 14]\n",
      "File Amalia 2 loaded\n",
      "Non-Atentie ./Recordings/Amalia 2/subj-1_ses-S004_task-Amalia 2 vid non-attention_run-001_20240819_104704_eeg_2d2a04d7-1837-4c63-83b4-0464719e97fa-raw.fif\n",
      "<Raw | subj-1_ses-S004_task-Amalia 2 vid non-attention_run-001_20240819_104704_eeg_2d2a04d7-1837-4c63-83b4-0464719e97fa-raw.fif, 21 x 83550 (334.2 s), ~13.4 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'muscle artifact', 'other', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'brain', 'other']\n",
      "Excluding these ICA components[1, 2, 14]\n",
      "File Andrei 2 loaded\n",
      "Atentie ./Recordings/Andrei 2/subj-1_ses-S006_task-Andrei vid attention 2_run-001_20240819_130153_eeg_0855b8da-c342-4526-bb56-d8cbab36c9b0-raw.fif\n",
      "<Raw | subj-1_ses-S006_task-Andrei vid attention 2_run-001_20240819_130153_eeg_0855b8da-c342-4526-bb56-d8cbab36c9b0-raw.fif, 21 x 87575 (350.3 s), ~14.1 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'other', 'brain', 'other', 'other', 'other', 'brain', 'brain', 'other']\n",
      "Excluding these ICA components[2, 7, 9, 10, 11, 14]\n",
      "Non-Atentie ./Recordings/Andrei 2/subj-1_ses-S003_task-Andrei2 vid non-attention_run-001_20240820_164827_eeg_03099e9c-5447-47c3-ad06-c2c8da94b24d-raw.fif\n",
      "<Raw | subj-1_ses-S003_task-Andrei2 vid non-attention_run-001_20240820_164827_eeg_03099e9c-5447-47c3-ad06-c2c8da94b24d-raw.fif, 21 x 79000 (316.0 s), ~12.7 MB, data loaded>\n",
      "['P8', 'O2', 'P4', 'C4', 'F8', 'F4', 'Oz', 'Cz', 'Fz', 'Pz', 'F3', 'O1', 'P7', 'C3', 'P3', 'F7', 'Accel_x', 'Accel_y', 'Accel_z', 'Digital', 'Battery']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'other', 'brain', 'other', 'eye blink', 'other', 'brain', 'brain', 'eye blink', 'brain', 'other', 'brain', 'brain', 'brain', 'brain']\n",
      "Excluding these ICA components[1, 3, 4, 5, 8, 10]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:22.045912Z",
     "start_time": "2024-08-30T08:03:22.043076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Shape of X_Blue: {X_Blue.shape}\")\n",
    "print(f\"Shape of y_Blue: {y_Blue.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_Blue: (494, 16, 1000)\n",
      "Shape of y_Blue: (494,)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:22.144621Z",
     "start_time": "2024-08-30T08:03:22.103040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Combine in X_all all of the X's with numpy.concatenate\n",
    "X_all = np.concatenate((X_Blue, X_Galben, X_mov, X_Verde), axis=0)\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:22.157982Z",
     "start_time": "2024-08-30T08:03:22.155504Z"
    }
   },
   "cell_type": "code",
   "source": "y_all = np.concatenate((y_Blue, y_Galben, y_mov, y_Verde), axis=0)",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:22.256256Z",
     "start_time": "2024-08-30T08:03:22.253690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Shape of X_all: {X_all.shape}\")\n",
    "print(f\"Shape of y_all: {y_all.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_all: (1993, 16, 1000)\n",
      "Shape of y_all: (1993,)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:11:16.337860Z",
     "start_time": "2024-08-30T14:11:16.307944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "                \n",
    "        # LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_size=10, hidden_size=25, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=25, hidden_size=50, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=50, hidden_size=75, batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(input_size=75, hidden_size=125, batch_first=True)\n",
    "        \n",
    "        # Activation function for LSTM layers\n",
    "        self.lstm_activation = nn.Tanh()\n",
    "        \n",
    "        # Upsampling convolution blocks\n",
    "        self.upsample1 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.upsample2 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        \n",
    "        self.upsample3 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        \n",
    "        self.upsample4 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation4 = nn.ReLU()\n",
    "        \n",
    "        # Downsampling blocks\n",
    "        self.downsample1 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.downsample_activation = nn.ReLU()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Reshape input\n",
    "        x = x.view(-1, 16, 10)\n",
    "        \n",
    "        # LSTM layers\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        \n",
    "        # Permute to match Conv1d input shape (batch_size, channels, sequence_length)\n",
    "        # Upsampling convolution blocks\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.upsample4(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Downsampling layer\n",
    "        x = self.downsample1(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "generator = Generator()\n",
    "input_tensor = torch.randn(160)  # Batch size of 1, input size of 160\n",
    "output = generator(input_tensor)\n",
    "print(output.shape)  # Should be (1, 16, 1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000, 16])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:11:18.997102Z",
     "start_time": "2024-08-30T14:11:18.979119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation1 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation2 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation3 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation4 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(16128, 1)  # Adjust the input size based on the output of the last conv layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.activation3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.activation4(x)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "discriminator = Discriminator()\n",
    "input_tensor = torch.randn(64, 16, 1000)  # Batch size of 1, 16 channels, sequence length of 1000\n",
    "output = discriminator(input_tensor)\n",
    "print(output.shape)  # Should be (1, 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:11:25.828014Z",
     "start_time": "2024-08-30T14:11:25.824773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def get_dataloader(X_all,y_all):\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            sample = self.X[idx]\n",
    "            label = self.y[idx]\n",
    "            return sample, label\n",
    "    # Assuming X_all and y_all are numpy arrays or similar\n",
    "    X_all_tensor = torch.tensor(X_all, dtype=torch.float32)\n",
    "    y_all_tensor = torch.tensor(y_all, dtype=torch.float32)\n",
    "    # Create dataset\n",
    "    dataset = CustomDataset(X_all_tensor, y_all_tensor)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    return dataloader\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T08:03:40.052033Z",
     "start_time": "2024-08-30T08:03:40.006230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Blue_dataloader = get_dataloader(X_Blue, y_Blue)\n",
    "Verde_dataloader = get_dataloader(X_Verde, y_Verde)\n",
    "Galbe_dataloader = get_dataloader(X_Galben, y_Galben)\n",
    "Mov_dataloader = get_dataloader(X_mov,  y_mov)\n",
    "All_dataloader = get_dataloader(X_all, y_all)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:11:31.484592Z",
     "start_time": "2024-08-30T14:11:31.469718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, grad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the Generator and Discriminator classes (as provided)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, 16)\n",
    "        self.conv1 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation1 = nn.LeakyReLU(0.2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation2 = nn.LeakyReLU(0.2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation3 = nn.LeakyReLU(0.2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.activation4 = nn.LeakyReLU(0.2)\n",
    "        self.fc = nn.Linear(16128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.activation4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, 16)\n",
    "        self.lstm1 = nn.LSTM(input_size=10, hidden_size=125, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=25, hidden_size=50, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=50, hidden_size=75, batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(input_size=75, hidden_size=125, batch_first=True)\n",
    "        self.lstm_activation = nn.Tanh()\n",
    "        self.upsample1 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.batch_norch1 = nn.BatchNorm1d(16)\n",
    "        self.relu_layer1 = nn.ReLU()\n",
    "        self.resblock1 = ResidualBlock(16)\n",
    "        self.upsample2 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.resblock2 = ResidualBlock(16)\n",
    "        self.upsample3 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        self.resblock3 = ResidualBlock(16)\n",
    "        self.upsample4 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.activation4 = nn.ReLU()\n",
    "        self.resblock4 = ResidualBlock(16)\n",
    "        self.downsample1 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.downsample_activation = nn.ReLU()\n",
    "                \n",
    "    def forward(self, x, labels):\n",
    "        label_embedding = self.label_embedding(labels).unsqueeze(2)\n",
    "        x = torch.cat([x, label_embedding], dim=1)\n",
    "        x = x.view(-1, 16, 10)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norch1(x)\n",
    "        x = self.relu_layer1(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv2(x)        \n",
    "        x = self.batch_norch1(x)\n",
    "        x = self.relu_layer1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.upsample3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norch1(x)\n",
    "        x = self.relu_layer1(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.upsample4(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch_norch1(x)\n",
    "        x = self.relu_layer1(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.downsample1(x)\n",
    "        return x\n",
    "def train_multi_generator_conditional_wasserstein_GAN_color(color, dataloader):\n",
    "    # Initialize models\n",
    "    num_classes = 10  # Example number of classes\n",
    "    generator = Generator(num_classes)\n",
    "    discriminator = Discriminator(num_classes)\n",
    "    \n",
    "    # Optimizersmodel\n",
    "    lr = 0.00005\n",
    "    optimizer_G = optim.RMSprop(generator.parameters(), lr=lr)\n",
    "    optimizer_D = optim.RMSprop(discriminator.parameters(), lr=lr)\n",
    "    \n",
    "    # Training parameters\n",
    "    n_epochs = 100\n",
    "    n_critic = 7\n",
    "    lambda_gp = 5\n",
    "    \n",
    "    # Create directories for saving images\n",
    "    os.makedirs(f'./plots_{color}/fake', exist_ok=True)\n",
    "    os.makedirs(f'./plots_{color}/real', exist_ok=True)\n",
    "    \n",
    "    def save_image_and_psd(data, epoch, label):\n",
    "        # Save the image\n",
    "        plt.figure()\n",
    "        plt.plot(data[0].cpu().detach().numpy())\n",
    "        plt.title(f'{label} Image Epoch {epoch}')\n",
    "        plt.savefig(f'./plots_{color}/{label}/{label}_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "    \n",
    "        # Compute and save the PSD\n",
    "        psd = np.abs(np.fft.fft(data[0].cpu().detach().numpy()))**2\n",
    "        freqs = np.fft.fftfreq(len(psd))\n",
    "        plt.figure()\n",
    "        plt.plot(freqs, psd)\n",
    "        plt.title(f'{label} PSD Epoch {epoch}')\n",
    "        plt.savefig(f'./plots_{color}/{label}/{label}_psd_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, (real_data, labels) in enumerate(dataloader):\n",
    "            real_data = real_data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            for _ in range(n_critic):\n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # Sample noise and generate fake data\n",
    "                noise = torch.randn(real_data.size(0), 144, 1).to(device)\n",
    "                generator.to(device)\n",
    "                labels = labels.to(device).long()\n",
    "                fake_data = generator(noise, labels)\n",
    "                # Discriminator loss\n",
    "                real_data.to(device)\n",
    "                discriminator.to(device)\n",
    "                \n",
    "                real_validity = discriminator(real_data)\n",
    "                fake_validity = discriminator(fake_data)\n",
    "                d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "                \n",
    "                # Gradient penalty\n",
    "                alpha = torch.rand(real_data.size(0), 1, 1).to(device)\n",
    "                interpolates = (alpha * real_data + ((1 - alpha) * fake_data)).requires_grad_(True)\n",
    "                d_interpolates = discriminator(interpolates)\n",
    "                fake = Variable(torch.Tensor(real_data.shape[0], 1).fill_(1.0), requires_grad=False).to(device)\n",
    "                gradients = grad(outputs=d_interpolates, inputs=interpolates,\n",
    "                                 grad_outputs=fake, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "                gradients = gradients.view(gradients.size(0), -1)\n",
    "                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_gp\n",
    "                d_loss += gradient_penalty\n",
    "                \n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake data\n",
    "            noise = torch.randn(real_data.size(0), 144, 1).to(device)\n",
    "            fake_data = generator(noise, labels)\n",
    "            \n",
    "            # Generator loss\n",
    "            fake_validity = discriminator(fake_data)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step() \n",
    "        \n",
    "        # Save the first real and fake images and their PSDs\n",
    "        save_image_and_psd(real_data[0], epoch, 'real')\n",
    "        save_image_and_psd(fake_data[0], epoch, 'fake')\n",
    "        \n",
    "        # Print losses\n",
    "        print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "    return generator"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T11:14:24.992299Z",
     "start_time": "2024-08-30T11:14:24.990328Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T11:04:20.414378Z",
     "start_time": "2024-08-30T11:04:20.407251Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:12:41.447048Z",
     "start_time": "2024-08-30T14:12:41.439396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jenerator = Generator(10)\n",
    "discri = Discriminator(10)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:14:36.175624Z",
     "start_time": "2024-08-30T14:14:35.228386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "noise = torch.randn(64, 144, 1).to('cpu')\n",
    "jenerator.to('cpu')\n",
    "y = jenerator(noise, torch.tensor(np.full(64, 0)).long().to('cpu'))\n",
    "y_ = discri(y)\n",
    "from torchviz import make_dot\n",
    "make_dot(y_, params=dict(list(discri.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn_torchviz.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T11:05:35.161829Z",
     "start_time": "2024-08-30T11:05:35.138122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 16\n",
    "summary(jenerator)"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Generator' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchinfo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary\n\u001B[1;32m      3\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjenerator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torchinfo/torchinfo.py:212\u001B[0m, in \u001B[0;36msummary\u001B[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     cache_forward_pass \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 212\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[43mget_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    214\u001B[0m     device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(device)\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torchinfo/torchinfo.py:481\u001B[0m, in \u001B[0;36mget_device\u001B[0;34m(model, input_data)\u001B[0m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 481\u001B[0m         model_parameter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m())\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    483\u001B[0m         model_parameter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Generator' object has no attribute 'parameters'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-28T12:56:52.603707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "all_generator = train_multi_generator_conditional_wasserstein_GAN_color(\"all\", All_dataloader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:52:35.940144Z",
     "start_time": "2024-08-28T06:50:09.831115Z"
    }
   },
   "cell_type": "code",
   "source": "mov_generator = train_multi_generator_conditional_wasserstein_GAN_color(\"mov\", Mov_dataloader)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [D loss: -47.03122329711914] [G loss: 53.260597229003906]\n",
      "[Epoch 1/100] [D loss: -39.386024475097656] [G loss: 55.397865295410156]\n",
      "[Epoch 2/100] [D loss: -36.17995834350586] [G loss: 46.32733917236328]\n",
      "[Epoch 3/100] [D loss: -37.73249435424805] [G loss: 45.23401641845703]\n",
      "[Epoch 4/100] [D loss: -42.74073028564453] [G loss: 47.01251220703125]\n",
      "[Epoch 5/100] [D loss: -49.558006286621094] [G loss: 50.01932144165039]\n",
      "[Epoch 6/100] [D loss: -45.60081100463867] [G loss: 45.05743408203125]\n",
      "[Epoch 7/100] [D loss: -40.14418029785156] [G loss: 37.06263732910156]\n",
      "[Epoch 8/100] [D loss: -33.597869873046875] [G loss: 29.095706939697266]\n",
      "[Epoch 9/100] [D loss: -28.297515869140625] [G loss: 21.286376953125]\n",
      "[Epoch 10/100] [D loss: -26.138107299804688] [G loss: 16.530315399169922]\n",
      "[Epoch 11/100] [D loss: -25.947071075439453] [G loss: 14.674764633178711]\n",
      "[Epoch 12/100] [D loss: -27.63977813720703] [G loss: 13.177321434020996]\n",
      "[Epoch 13/100] [D loss: -27.969514846801758] [G loss: 12.13789176940918]\n",
      "[Epoch 14/100] [D loss: -28.115478515625] [G loss: 10.285247802734375]\n",
      "[Epoch 15/100] [D loss: -29.797107696533203] [G loss: 10.248909950256348]\n",
      "[Epoch 16/100] [D loss: -26.539844512939453] [G loss: 6.309160232543945]\n",
      "[Epoch 17/100] [D loss: -25.3516788482666] [G loss: 4.186098098754883]\n",
      "[Epoch 18/100] [D loss: -25.200733184814453] [G loss: 2.940390110015869]\n",
      "[Epoch 19/100] [D loss: -22.576251983642578] [G loss: -2.2154574394226074]\n",
      "[Epoch 20/100] [D loss: -22.21710777282715] [G loss: -4.882336616516113]\n",
      "[Epoch 21/100] [D loss: -21.13863754272461] [G loss: -7.611536026000977]\n",
      "[Epoch 22/100] [D loss: -19.243091583251953] [G loss: -11.356704711914062]\n",
      "[Epoch 23/100] [D loss: -18.911170959472656] [G loss: -14.041080474853516]\n",
      "[Epoch 24/100] [D loss: -18.318347930908203] [G loss: -15.587116241455078]\n",
      "[Epoch 25/100] [D loss: -17.090856552124023] [G loss: -18.047550201416016]\n",
      "[Epoch 26/100] [D loss: -16.648401260375977] [G loss: -19.183738708496094]\n",
      "[Epoch 27/100] [D loss: -15.592241287231445] [G loss: -20.806995391845703]\n",
      "[Epoch 28/100] [D loss: -14.823530197143555] [G loss: -21.62265968322754]\n",
      "[Epoch 29/100] [D loss: -14.30092716217041] [G loss: -22.72146987915039]\n",
      "[Epoch 30/100] [D loss: -14.248332977294922] [G loss: -23.334514617919922]\n",
      "[Epoch 31/100] [D loss: -13.414684295654297] [G loss: -24.575796127319336]\n",
      "[Epoch 32/100] [D loss: -13.126191139221191] [G loss: -24.942649841308594]\n",
      "[Epoch 33/100] [D loss: -12.6678466796875] [G loss: -24.86018943786621]\n",
      "[Epoch 34/100] [D loss: -12.382083892822266] [G loss: -24.480152130126953]\n",
      "[Epoch 35/100] [D loss: -11.958462715148926] [G loss: -23.847488403320312]\n",
      "[Epoch 36/100] [D loss: -11.608057975769043] [G loss: -24.163692474365234]\n",
      "[Epoch 37/100] [D loss: -11.407336235046387] [G loss: -24.36874771118164]\n",
      "[Epoch 38/100] [D loss: -10.392461776733398] [G loss: -25.530166625976562]\n",
      "[Epoch 39/100] [D loss: -9.916766166687012] [G loss: -25.69595718383789]\n",
      "[Epoch 40/100] [D loss: -9.627800941467285] [G loss: -25.648582458496094]\n",
      "[Epoch 41/100] [D loss: -9.156309127807617] [G loss: -25.485055923461914]\n",
      "[Epoch 42/100] [D loss: -8.57221508026123] [G loss: -26.039047241210938]\n",
      "[Epoch 43/100] [D loss: -8.299337387084961] [G loss: -26.682682037353516]\n",
      "[Epoch 44/100] [D loss: -7.835771560668945] [G loss: -26.378774642944336]\n",
      "[Epoch 45/100] [D loss: -7.459622383117676] [G loss: -27.16986656188965]\n",
      "[Epoch 46/100] [D loss: -7.325045108795166] [G loss: -26.1368350982666]\n",
      "[Epoch 47/100] [D loss: -6.848602771759033] [G loss: -26.896690368652344]\n",
      "[Epoch 48/100] [D loss: -6.58095645904541] [G loss: -26.379087448120117]\n",
      "[Epoch 49/100] [D loss: -6.385525703430176] [G loss: -25.399105072021484]\n",
      "[Epoch 50/100] [D loss: -6.245340347290039] [G loss: -25.279273986816406]\n",
      "[Epoch 51/100] [D loss: -5.958723068237305] [G loss: -25.01193618774414]\n",
      "[Epoch 52/100] [D loss: -5.6207780838012695] [G loss: -24.528667449951172]\n",
      "[Epoch 53/100] [D loss: -5.395271301269531] [G loss: -24.009807586669922]\n",
      "[Epoch 54/100] [D loss: -5.320213317871094] [G loss: -22.68110466003418]\n",
      "[Epoch 55/100] [D loss: -5.100045680999756] [G loss: -22.515064239501953]\n",
      "[Epoch 56/100] [D loss: -4.813658714294434] [G loss: -22.389909744262695]\n",
      "[Epoch 57/100] [D loss: -4.713860034942627] [G loss: -22.29534149169922]\n",
      "[Epoch 58/100] [D loss: -4.466754913330078] [G loss: -21.44519805908203]\n",
      "[Epoch 59/100] [D loss: -4.352673053741455] [G loss: -21.263580322265625]\n",
      "[Epoch 60/100] [D loss: -4.113552570343018] [G loss: -21.483673095703125]\n",
      "[Epoch 61/100] [D loss: -4.0518364906311035] [G loss: -20.861494064331055]\n",
      "[Epoch 62/100] [D loss: -3.9449167251586914] [G loss: -20.374794006347656]\n",
      "[Epoch 63/100] [D loss: -3.768772840499878] [G loss: -20.04928207397461]\n",
      "[Epoch 64/100] [D loss: -3.581545352935791] [G loss: -19.608200073242188]\n",
      "[Epoch 65/100] [D loss: -3.5175013542175293] [G loss: -19.53390121459961]\n",
      "[Epoch 66/100] [D loss: -3.3141486644744873] [G loss: -19.153202056884766]\n",
      "[Epoch 67/100] [D loss: -3.171834945678711] [G loss: -19.3376522064209]\n",
      "[Epoch 68/100] [D loss: -3.1707069873809814] [G loss: -18.735382080078125]\n",
      "[Epoch 69/100] [D loss: -3.0012331008911133] [G loss: -18.831937789916992]\n",
      "[Epoch 70/100] [D loss: -2.898609161376953] [G loss: -18.41312599182129]\n",
      "[Epoch 71/100] [D loss: -2.7912349700927734] [G loss: -18.13597869873047]\n",
      "[Epoch 72/100] [D loss: -2.7294046878814697] [G loss: -17.98592758178711]\n",
      "[Epoch 73/100] [D loss: -2.538203716278076] [G loss: -18.043838500976562]\n",
      "[Epoch 74/100] [D loss: -2.4607527256011963] [G loss: -17.723007202148438]\n",
      "[Epoch 75/100] [D loss: -2.5116279125213623] [G loss: -17.519689559936523]\n",
      "[Epoch 76/100] [D loss: -2.3495028018951416] [G loss: -17.114456176757812]\n",
      "[Epoch 77/100] [D loss: -2.343946695327759] [G loss: -17.192054748535156]\n",
      "[Epoch 78/100] [D loss: -2.2195489406585693] [G loss: -16.850984573364258]\n",
      "[Epoch 79/100] [D loss: -2.2389464378356934] [G loss: -16.740739822387695]\n",
      "[Epoch 80/100] [D loss: -2.1285932064056396] [G loss: -16.590255737304688]\n",
      "[Epoch 81/100] [D loss: -2.1240270137786865] [G loss: -16.233121871948242]\n",
      "[Epoch 82/100] [D loss: -2.0507609844207764] [G loss: -16.412532806396484]\n",
      "[Epoch 83/100] [D loss: -1.9820020198822021] [G loss: -16.309410095214844]\n",
      "[Epoch 84/100] [D loss: -1.9452885389328003] [G loss: -16.275257110595703]\n",
      "[Epoch 85/100] [D loss: -1.9781529903411865] [G loss: -15.568977355957031]\n",
      "[Epoch 86/100] [D loss: -1.977888584136963] [G loss: -14.669164657592773]\n",
      "[Epoch 87/100] [D loss: -1.7980564832687378] [G loss: -15.466473579406738]\n",
      "[Epoch 88/100] [D loss: -1.7831695079803467] [G loss: -15.939254760742188]\n",
      "[Epoch 89/100] [D loss: -1.7282730340957642] [G loss: -16.028152465820312]\n",
      "[Epoch 90/100] [D loss: -1.7632298469543457] [G loss: -15.69417953491211]\n",
      "[Epoch 91/100] [D loss: -1.6495633125305176] [G loss: -15.677005767822266]\n",
      "[Epoch 92/100] [D loss: -1.6160755157470703] [G loss: -15.400206565856934]\n",
      "[Epoch 93/100] [D loss: -1.6107678413391113] [G loss: -15.326696395874023]\n",
      "[Epoch 94/100] [D loss: -1.5556966066360474] [G loss: -15.467554092407227]\n",
      "[Epoch 95/100] [D loss: -1.4887148141860962] [G loss: -15.139219284057617]\n",
      "[Epoch 96/100] [D loss: -1.5820879936218262] [G loss: -15.129095077514648]\n",
      "[Epoch 97/100] [D loss: -1.4777058362960815] [G loss: -14.957073211669922]\n",
      "[Epoch 98/100] [D loss: -1.4573266506195068] [G loss: -14.753150939941406]\n",
      "[Epoch 99/100] [D loss: -1.4609637260437012] [G loss: -14.50072956085205]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:55:57.882786Z",
     "start_time": "2024-08-28T06:52:35.955579Z"
    }
   },
   "cell_type": "code",
   "source": "Blue_generator = train_multi_generator_conditional_wasserstein_GAN_color(\"albastru\", Blue_dataloader)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [D loss: -54.352439880371094] [G loss: 73.17938995361328]\n",
      "[Epoch 1/100] [D loss: -55.51062774658203] [G loss: 78.24891662597656]\n",
      "[Epoch 2/100] [D loss: -52.619895935058594] [G loss: 70.7457275390625]\n",
      "[Epoch 3/100] [D loss: -45.158363342285156] [G loss: 59.20725631713867]\n",
      "[Epoch 4/100] [D loss: -41.75315475463867] [G loss: 47.868324279785156]\n",
      "[Epoch 5/100] [D loss: -41.531578063964844] [G loss: 37.83442687988281]\n",
      "[Epoch 6/100] [D loss: -39.775909423828125] [G loss: 28.381942749023438]\n",
      "[Epoch 7/100] [D loss: -38.888153076171875] [G loss: 20.43448257446289]\n",
      "[Epoch 8/100] [D loss: -37.091609954833984] [G loss: 14.191330909729004]\n",
      "[Epoch 9/100] [D loss: -34.8323974609375] [G loss: 11.270087242126465]\n",
      "[Epoch 10/100] [D loss: -35.148170471191406] [G loss: 9.037969589233398]\n",
      "[Epoch 11/100] [D loss: -34.235328674316406] [G loss: 7.300290584564209]\n",
      "[Epoch 12/100] [D loss: -32.10527420043945] [G loss: 6.534210205078125]\n",
      "[Epoch 13/100] [D loss: -29.754840850830078] [G loss: 2.6290838718414307]\n",
      "[Epoch 14/100] [D loss: -29.26202392578125] [G loss: -0.6237746477127075]\n",
      "[Epoch 15/100] [D loss: -28.32096290588379] [G loss: -3.0100483894348145]\n",
      "[Epoch 16/100] [D loss: -26.805789947509766] [G loss: -5.259692192077637]\n",
      "[Epoch 17/100] [D loss: -25.94935417175293] [G loss: -7.094377040863037]\n",
      "[Epoch 18/100] [D loss: -24.883098602294922] [G loss: -7.92569637298584]\n",
      "[Epoch 19/100] [D loss: -23.30799102783203] [G loss: -9.683377265930176]\n",
      "[Epoch 20/100] [D loss: -21.83653450012207] [G loss: -10.055057525634766]\n",
      "[Epoch 21/100] [D loss: -21.221691131591797] [G loss: -11.539278984069824]\n",
      "[Epoch 22/100] [D loss: -20.30242156982422] [G loss: -11.832587242126465]\n",
      "[Epoch 23/100] [D loss: -18.624435424804688] [G loss: -13.539580345153809]\n",
      "[Epoch 24/100] [D loss: -17.93956756591797] [G loss: -12.990663528442383]\n",
      "[Epoch 25/100] [D loss: -17.331470489501953] [G loss: -12.375653266906738]\n",
      "[Epoch 26/100] [D loss: -15.900407791137695] [G loss: -12.90434455871582]\n",
      "[Epoch 27/100] [D loss: -15.179067611694336] [G loss: -12.740349769592285]\n",
      "[Epoch 28/100] [D loss: -14.40802001953125] [G loss: -11.997658729553223]\n",
      "[Epoch 29/100] [D loss: -13.208698272705078] [G loss: -13.245759963989258]\n",
      "[Epoch 30/100] [D loss: -12.630780220031738] [G loss: -13.60436725616455]\n",
      "[Epoch 31/100] [D loss: -11.945911407470703] [G loss: -14.12025260925293]\n",
      "[Epoch 32/100] [D loss: -10.99098014831543] [G loss: -14.33642292022705]\n",
      "[Epoch 33/100] [D loss: -9.9994535446167] [G loss: -14.431111335754395]\n",
      "[Epoch 34/100] [D loss: -9.85342788696289] [G loss: -14.652960777282715]\n",
      "[Epoch 35/100] [D loss: -9.04782485961914] [G loss: -15.003437042236328]\n",
      "[Epoch 36/100] [D loss: -8.51823616027832] [G loss: -15.441198348999023]\n",
      "[Epoch 37/100] [D loss: -8.068939208984375] [G loss: -15.67789077758789]\n",
      "[Epoch 38/100] [D loss: -7.677096843719482] [G loss: -15.447956085205078]\n",
      "[Epoch 39/100] [D loss: -7.299849510192871] [G loss: -14.674871444702148]\n",
      "[Epoch 40/100] [D loss: -6.675182342529297] [G loss: -14.86070728302002]\n",
      "[Epoch 41/100] [D loss: -6.557648181915283] [G loss: -14.03666877746582]\n",
      "[Epoch 42/100] [D loss: -6.1670145988464355] [G loss: -13.95435905456543]\n",
      "[Epoch 43/100] [D loss: -5.896149635314941] [G loss: -13.272266387939453]\n",
      "[Epoch 44/100] [D loss: -5.474391937255859] [G loss: -13.43398380279541]\n",
      "[Epoch 45/100] [D loss: -5.404479026794434] [G loss: -13.423057556152344]\n",
      "[Epoch 46/100] [D loss: -5.034461975097656] [G loss: -12.986430168151855]\n",
      "[Epoch 47/100] [D loss: -4.800609111785889] [G loss: -13.32335090637207]\n",
      "[Epoch 48/100] [D loss: -4.579742431640625] [G loss: -13.000289916992188]\n",
      "[Epoch 49/100] [D loss: -4.464951515197754] [G loss: -12.92245864868164]\n",
      "[Epoch 50/100] [D loss: -4.16924524307251] [G loss: -12.32730770111084]\n",
      "[Epoch 51/100] [D loss: -4.049345016479492] [G loss: -12.14872932434082]\n",
      "[Epoch 52/100] [D loss: -3.887683391571045] [G loss: -12.428462028503418]\n",
      "[Epoch 53/100] [D loss: -3.7652499675750732] [G loss: -11.904455184936523]\n",
      "[Epoch 54/100] [D loss: -3.551827907562256] [G loss: -11.887341499328613]\n",
      "[Epoch 55/100] [D loss: -3.507783889770508] [G loss: -11.943581581115723]\n",
      "[Epoch 56/100] [D loss: -3.3540093898773193] [G loss: -11.711041450500488]\n",
      "[Epoch 57/100] [D loss: -3.2455761432647705] [G loss: -11.700397491455078]\n",
      "[Epoch 58/100] [D loss: -3.079900026321411] [G loss: -11.33610725402832]\n",
      "[Epoch 59/100] [D loss: -3.0061793327331543] [G loss: -11.150619506835938]\n",
      "[Epoch 60/100] [D loss: -2.9191529750823975] [G loss: -11.151026725769043]\n",
      "[Epoch 61/100] [D loss: -2.7603447437286377] [G loss: -10.879480361938477]\n",
      "[Epoch 62/100] [D loss: -2.7048957347869873] [G loss: -10.541671752929688]\n",
      "[Epoch 63/100] [D loss: -2.667038917541504] [G loss: -10.46130657196045]\n",
      "[Epoch 64/100] [D loss: -2.617849826812744] [G loss: -10.017034530639648]\n",
      "[Epoch 65/100] [D loss: -2.5020599365234375] [G loss: -9.240386009216309]\n",
      "[Epoch 66/100] [D loss: -2.4173436164855957] [G loss: -9.186258316040039]\n",
      "[Epoch 67/100] [D loss: -2.313241958618164] [G loss: -8.9772310256958]\n",
      "[Epoch 68/100] [D loss: -2.300811767578125] [G loss: -8.6340970993042]\n",
      "[Epoch 69/100] [D loss: -2.211172580718994] [G loss: -8.081716537475586]\n",
      "[Epoch 70/100] [D loss: -2.1412193775177] [G loss: -8.072408676147461]\n",
      "[Epoch 71/100] [D loss: -2.1929659843444824] [G loss: -7.474959850311279]\n",
      "[Epoch 72/100] [D loss: -2.0753185749053955] [G loss: -7.353418350219727]\n",
      "[Epoch 73/100] [D loss: -2.023353099822998] [G loss: -7.521299362182617]\n",
      "[Epoch 74/100] [D loss: -1.9944349527359009] [G loss: -6.947218418121338]\n",
      "[Epoch 75/100] [D loss: -1.8901931047439575] [G loss: -6.81556510925293]\n",
      "[Epoch 76/100] [D loss: -1.8264014720916748] [G loss: -6.8773512840271]\n",
      "[Epoch 77/100] [D loss: -1.8204610347747803] [G loss: -6.870027542114258]\n",
      "[Epoch 78/100] [D loss: -1.8618130683898926] [G loss: -6.225909233093262]\n",
      "[Epoch 79/100] [D loss: -1.713484525680542] [G loss: -6.519130706787109]\n",
      "[Epoch 80/100] [D loss: -1.6636568307876587] [G loss: -6.166561126708984]\n",
      "[Epoch 81/100] [D loss: -1.6415951251983643] [G loss: -6.242588520050049]\n",
      "[Epoch 82/100] [D loss: -1.6184760332107544] [G loss: -6.171905517578125]\n",
      "[Epoch 83/100] [D loss: -1.6198909282684326] [G loss: -5.915454387664795]\n",
      "[Epoch 84/100] [D loss: -1.5700464248657227] [G loss: -5.849581718444824]\n",
      "[Epoch 85/100] [D loss: -1.591769814491272] [G loss: -5.727299213409424]\n",
      "[Epoch 86/100] [D loss: -1.5258454084396362] [G loss: -5.644137382507324]\n",
      "[Epoch 87/100] [D loss: -1.519542932510376] [G loss: -5.690483570098877]\n",
      "[Epoch 88/100] [D loss: -1.4869786500930786] [G loss: -5.698173999786377]\n",
      "[Epoch 89/100] [D loss: -1.4157330989837646] [G loss: -5.60878324508667]\n",
      "[Epoch 90/100] [D loss: -1.388964295387268] [G loss: -5.663443565368652]\n",
      "[Epoch 91/100] [D loss: -1.4005883932113647] [G loss: -5.347796440124512]\n",
      "[Epoch 92/100] [D loss: -1.3644771575927734] [G loss: -5.4689741134643555]\n",
      "[Epoch 93/100] [D loss: -1.4031684398651123] [G loss: -5.437669277191162]\n",
      "[Epoch 94/100] [D loss: -1.3747272491455078] [G loss: -5.315956115722656]\n",
      "[Epoch 95/100] [D loss: -1.303187608718872] [G loss: -5.3307881355285645]\n",
      "[Epoch 96/100] [D loss: -1.2955912351608276] [G loss: -5.434174537658691]\n",
      "[Epoch 97/100] [D loss: -1.2966521978378296] [G loss: -5.065896034240723]\n",
      "[Epoch 98/100] [D loss: -1.2651517391204834] [G loss: -5.363458633422852]\n",
      "[Epoch 99/100] [D loss: -1.2576922178268433] [G loss: -5.399229526519775]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:59:56.404794Z",
     "start_time": "2024-08-28T06:55:57.898563Z"
    }
   },
   "cell_type": "code",
   "source": "green_generator = train_multi_generator_conditional_wasserstein_GAN_color(\"verde\", Verde_dataloader)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [D loss: -39.712379455566406] [G loss: 48.1855583190918]\n",
      "[Epoch 1/100] [D loss: -35.738529205322266] [G loss: 35.96364212036133]\n",
      "[Epoch 2/100] [D loss: -47.9150505065918] [G loss: 38.011592864990234]\n",
      "[Epoch 3/100] [D loss: -51.95201873779297] [G loss: 41.050594329833984]\n",
      "[Epoch 4/100] [D loss: -43.934234619140625] [G loss: 33.5573616027832]\n",
      "[Epoch 5/100] [D loss: -31.352394104003906] [G loss: 14.455424308776855]\n",
      "[Epoch 6/100] [D loss: -28.03701400756836] [G loss: 6.459021091461182]\n",
      "[Epoch 7/100] [D loss: -26.926801681518555] [G loss: 2.6803901195526123]\n",
      "[Epoch 8/100] [D loss: -23.78362274169922] [G loss: 2.1669442653656006]\n",
      "[Epoch 9/100] [D loss: -21.35095977783203] [G loss: -0.43322283029556274]\n",
      "[Epoch 10/100] [D loss: -18.681720733642578] [G loss: -5.069909572601318]\n",
      "[Epoch 11/100] [D loss: -16.85502052307129] [G loss: -8.378981590270996]\n",
      "[Epoch 12/100] [D loss: -15.614399909973145] [G loss: -10.953923225402832]\n",
      "[Epoch 13/100] [D loss: -14.481529235839844] [G loss: -12.750831604003906]\n",
      "[Epoch 14/100] [D loss: -13.344832420349121] [G loss: -13.142054557800293]\n",
      "[Epoch 15/100] [D loss: -12.229656219482422] [G loss: -13.306012153625488]\n",
      "[Epoch 16/100] [D loss: -11.698783874511719] [G loss: -14.19775390625]\n",
      "[Epoch 17/100] [D loss: -11.135103225708008] [G loss: -13.751871109008789]\n",
      "[Epoch 18/100] [D loss: -10.749242782592773] [G loss: -11.950492858886719]\n",
      "[Epoch 19/100] [D loss: -9.926948547363281] [G loss: -12.919379234313965]\n",
      "[Epoch 20/100] [D loss: -9.483793258666992] [G loss: -12.435431480407715]\n",
      "[Epoch 21/100] [D loss: -8.971084594726562] [G loss: -11.973113059997559]\n",
      "[Epoch 22/100] [D loss: -8.612485885620117] [G loss: -13.029322624206543]\n",
      "[Epoch 23/100] [D loss: -8.05711841583252] [G loss: -12.698094367980957]\n",
      "[Epoch 24/100] [D loss: -7.6053786277771] [G loss: -12.629898071289062]\n",
      "[Epoch 25/100] [D loss: -7.200761795043945] [G loss: -12.324254035949707]\n",
      "[Epoch 26/100] [D loss: -6.748468399047852] [G loss: -12.5509672164917]\n",
      "[Epoch 27/100] [D loss: -6.302811622619629] [G loss: -13.483006477355957]\n",
      "[Epoch 28/100] [D loss: -5.9959821701049805] [G loss: -12.412140846252441]\n",
      "[Epoch 29/100] [D loss: -5.752665042877197] [G loss: -14.062678337097168]\n",
      "[Epoch 30/100] [D loss: -5.457685470581055] [G loss: -13.269479751586914]\n",
      "[Epoch 31/100] [D loss: -5.20796012878418] [G loss: -13.280572891235352]\n",
      "[Epoch 32/100] [D loss: -4.967380046844482] [G loss: -13.382196426391602]\n",
      "[Epoch 33/100] [D loss: -4.592360973358154] [G loss: -13.553240776062012]\n",
      "[Epoch 34/100] [D loss: -4.380192279815674] [G loss: -13.639167785644531]\n",
      "[Epoch 35/100] [D loss: -4.148938179016113] [G loss: -13.761268615722656]\n",
      "[Epoch 36/100] [D loss: -4.00423002243042] [G loss: -12.839471817016602]\n",
      "[Epoch 37/100] [D loss: -3.780890941619873] [G loss: -13.517230033874512]\n",
      "[Epoch 38/100] [D loss: -3.6011133193969727] [G loss: -12.995894432067871]\n",
      "[Epoch 39/100] [D loss: -3.4511091709136963] [G loss: -13.094487190246582]\n",
      "[Epoch 40/100] [D loss: -3.340381145477295] [G loss: -12.748960494995117]\n",
      "[Epoch 41/100] [D loss: -3.1094143390655518] [G loss: -12.943323135375977]\n",
      "[Epoch 42/100] [D loss: -2.954915761947632] [G loss: -12.424338340759277]\n",
      "[Epoch 43/100] [D loss: -2.8173437118530273] [G loss: -12.436453819274902]\n",
      "[Epoch 44/100] [D loss: -2.6938750743865967] [G loss: -11.951655387878418]\n",
      "[Epoch 45/100] [D loss: -2.5775563716888428] [G loss: -11.701299667358398]\n",
      "[Epoch 46/100] [D loss: -2.4177801609039307] [G loss: -11.593976020812988]\n",
      "[Epoch 47/100] [D loss: -2.3154945373535156] [G loss: -11.559999465942383]\n",
      "[Epoch 48/100] [D loss: -2.2022056579589844] [G loss: -11.384613990783691]\n",
      "[Epoch 49/100] [D loss: -2.114910125732422] [G loss: -11.118695259094238]\n",
      "[Epoch 50/100] [D loss: -2.039970874786377] [G loss: -11.241546630859375]\n",
      "[Epoch 51/100] [D loss: -1.9651334285736084] [G loss: -10.979792594909668]\n",
      "[Epoch 52/100] [D loss: -1.8532851934432983] [G loss: -10.587733268737793]\n",
      "[Epoch 53/100] [D loss: -1.7608586549758911] [G loss: -11.084822654724121]\n",
      "[Epoch 54/100] [D loss: -1.7311252355575562] [G loss: -10.2349214553833]\n",
      "[Epoch 55/100] [D loss: -1.6608587503433228] [G loss: -9.97406005859375]\n",
      "[Epoch 56/100] [D loss: -1.5934548377990723] [G loss: -9.913073539733887]\n",
      "[Epoch 57/100] [D loss: -1.4849684238433838] [G loss: -9.97292709350586]\n",
      "[Epoch 58/100] [D loss: -1.4432157278060913] [G loss: -9.514564514160156]\n",
      "[Epoch 59/100] [D loss: -1.4001370668411255] [G loss: -9.364773750305176]\n",
      "[Epoch 60/100] [D loss: -1.3818740844726562] [G loss: -9.15666389465332]\n",
      "[Epoch 61/100] [D loss: -1.321404218673706] [G loss: -9.197550773620605]\n",
      "[Epoch 62/100] [D loss: -1.3308930397033691] [G loss: -8.313881874084473]\n",
      "[Epoch 63/100] [D loss: -1.4052659273147583] [G loss: -7.5739030838012695]\n",
      "[Epoch 64/100] [D loss: -1.2670220136642456] [G loss: -7.738499641418457]\n",
      "[Epoch 65/100] [D loss: -1.2041903734207153] [G loss: -7.9303789138793945]\n",
      "[Epoch 66/100] [D loss: -1.1536831855773926] [G loss: -8.402141571044922]\n",
      "[Epoch 67/100] [D loss: -1.1190078258514404] [G loss: -8.1947660446167]\n",
      "[Epoch 68/100] [D loss: -1.141427993774414] [G loss: -6.972095012664795]\n",
      "[Epoch 69/100] [D loss: -1.1251015663146973] [G loss: -6.729825019836426]\n",
      "[Epoch 70/100] [D loss: -1.0766407251358032] [G loss: -7.2853102684021]\n",
      "[Epoch 71/100] [D loss: -1.0439114570617676] [G loss: -6.776151180267334]\n",
      "[Epoch 72/100] [D loss: -1.0125010013580322] [G loss: -6.762401103973389]\n",
      "[Epoch 73/100] [D loss: -0.9806416034698486] [G loss: -6.281839847564697]\n",
      "[Epoch 74/100] [D loss: -0.9586622714996338] [G loss: -6.636839389801025]\n",
      "[Epoch 75/100] [D loss: -0.9119196534156799] [G loss: -6.293986797332764]\n",
      "[Epoch 76/100] [D loss: -0.9233243465423584] [G loss: -6.240318298339844]\n",
      "[Epoch 77/100] [D loss: -0.9026187062263489] [G loss: -6.477395534515381]\n",
      "[Epoch 78/100] [D loss: -0.8745385408401489] [G loss: -6.164274215698242]\n",
      "[Epoch 79/100] [D loss: -0.8454391956329346] [G loss: -6.39515495300293]\n",
      "[Epoch 80/100] [D loss: -0.880411684513092] [G loss: -5.537286281585693]\n",
      "[Epoch 81/100] [D loss: -0.8714470863342285] [G loss: -5.047135829925537]\n",
      "[Epoch 82/100] [D loss: -0.8655472993850708] [G loss: -5.142163276672363]\n",
      "[Epoch 83/100] [D loss: -0.8249378800392151] [G loss: -5.1471781730651855]\n",
      "[Epoch 84/100] [D loss: -0.8220652341842651] [G loss: -5.245719909667969]\n",
      "[Epoch 85/100] [D loss: -0.7980734705924988] [G loss: -5.907742500305176]\n",
      "[Epoch 86/100] [D loss: -0.8370634913444519] [G loss: -5.21259069442749]\n",
      "[Epoch 87/100] [D loss: -0.8606029152870178] [G loss: -5.126950740814209]\n",
      "[Epoch 88/100] [D loss: -0.8382748365402222] [G loss: -4.9309539794921875]\n",
      "[Epoch 89/100] [D loss: -0.8061599731445312] [G loss: -4.903898239135742]\n",
      "[Epoch 90/100] [D loss: -0.7981039881706238] [G loss: -5.071625709533691]\n",
      "[Epoch 91/100] [D loss: -0.7817716598510742] [G loss: -4.793184757232666]\n",
      "[Epoch 92/100] [D loss: -0.7728147506713867] [G loss: -4.7304911613464355]\n",
      "[Epoch 93/100] [D loss: -0.7376166582107544] [G loss: -4.436478614807129]\n",
      "[Epoch 94/100] [D loss: -0.7474441528320312] [G loss: -4.623180389404297]\n",
      "[Epoch 95/100] [D loss: -0.7440634965896606] [G loss: -4.752138614654541]\n",
      "[Epoch 96/100] [D loss: -0.7108160853385925] [G loss: -4.745617866516113]\n",
      "[Epoch 97/100] [D loss: -0.7039481997489929] [G loss: -4.624197959899902]\n",
      "[Epoch 98/100] [D loss: -0.7144358158111572] [G loss: -4.4801225662231445]\n",
      "[Epoch 99/100] [D loss: -0.7059147953987122] [G loss: -4.9378557205200195]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:03:54.933241Z",
     "start_time": "2024-08-28T06:59:56.434377Z"
    }
   },
   "cell_type": "code",
   "source": "galbel_generator = train_multi_generator_conditional_wasserstein_GAN_color(\"galben\", Galbe_dataloader)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [D loss: -44.59037780761719] [G loss: 56.18569564819336]\n",
      "[Epoch 1/100] [D loss: -67.01216125488281] [G loss: 74.66055297851562]\n",
      "[Epoch 2/100] [D loss: -60.51124572753906] [G loss: 60.3524169921875]\n",
      "[Epoch 3/100] [D loss: -55.244449615478516] [G loss: 53.689823150634766]\n",
      "[Epoch 4/100] [D loss: -45.544471740722656] [G loss: 49.21670150756836]\n",
      "[Epoch 5/100] [D loss: -41.91961669921875] [G loss: 40.7409553527832]\n",
      "[Epoch 6/100] [D loss: -39.16326141357422] [G loss: 34.31304931640625]\n",
      "[Epoch 7/100] [D loss: -32.40407180786133] [G loss: 24.90779685974121]\n",
      "[Epoch 8/100] [D loss: -28.35179901123047] [G loss: 14.227249145507812]\n",
      "[Epoch 9/100] [D loss: -25.032485961914062] [G loss: 8.30870246887207]\n",
      "[Epoch 10/100] [D loss: -22.75323486328125] [G loss: 2.2216532230377197]\n",
      "[Epoch 11/100] [D loss: -20.905094146728516] [G loss: -1.0386244058609009]\n",
      "[Epoch 12/100] [D loss: -17.86876678466797] [G loss: -5.948613166809082]\n",
      "[Epoch 13/100] [D loss: -15.364495277404785] [G loss: -10.693943977355957]\n",
      "[Epoch 14/100] [D loss: -13.795280456542969] [G loss: -13.456376075744629]\n",
      "[Epoch 15/100] [D loss: -14.051250457763672] [G loss: -13.165708541870117]\n",
      "[Epoch 16/100] [D loss: -12.163591384887695] [G loss: -15.90256404876709]\n",
      "[Epoch 17/100] [D loss: -10.473430633544922] [G loss: -19.09037208557129]\n",
      "[Epoch 18/100] [D loss: -11.068734169006348] [G loss: -15.512721061706543]\n",
      "[Epoch 19/100] [D loss: -10.582383155822754] [G loss: -14.202149391174316]\n",
      "[Epoch 20/100] [D loss: -9.740763664245605] [G loss: -16.051538467407227]\n",
      "[Epoch 21/100] [D loss: -8.650092124938965] [G loss: -17.205705642700195]\n",
      "[Epoch 22/100] [D loss: -7.890280723571777] [G loss: -17.042850494384766]\n",
      "[Epoch 23/100] [D loss: -7.56734037399292] [G loss: -17.247005462646484]\n",
      "[Epoch 24/100] [D loss: -6.658953666687012] [G loss: -17.559236526489258]\n",
      "[Epoch 25/100] [D loss: -6.1702680587768555] [G loss: -18.805511474609375]\n",
      "[Epoch 26/100] [D loss: -6.05105447769165] [G loss: -18.29096221923828]\n",
      "[Epoch 27/100] [D loss: -5.440817356109619] [G loss: -19.368799209594727]\n",
      "[Epoch 28/100] [D loss: -5.401930809020996] [G loss: -18.775041580200195]\n",
      "[Epoch 29/100] [D loss: -4.889571189880371] [G loss: -19.03985595703125]\n",
      "[Epoch 30/100] [D loss: -5.008788108825684] [G loss: -17.79432487487793]\n",
      "[Epoch 31/100] [D loss: -4.681096076965332] [G loss: -17.134700775146484]\n",
      "[Epoch 32/100] [D loss: -4.393260478973389] [G loss: -16.71340560913086]\n",
      "[Epoch 33/100] [D loss: -4.115145683288574] [G loss: -15.852423667907715]\n",
      "[Epoch 34/100] [D loss: -3.716353178024292] [G loss: -16.830251693725586]\n",
      "[Epoch 35/100] [D loss: -3.6644015312194824] [G loss: -15.42054557800293]\n",
      "[Epoch 36/100] [D loss: -3.407245397567749] [G loss: -15.623988151550293]\n",
      "[Epoch 37/100] [D loss: -2.9874496459960938] [G loss: -14.671042442321777]\n",
      "[Epoch 38/100] [D loss: -3.0384249687194824] [G loss: -14.444461822509766]\n",
      "[Epoch 39/100] [D loss: -2.9976754188537598] [G loss: -14.349002838134766]\n",
      "[Epoch 40/100] [D loss: -2.7150216102600098] [G loss: -13.897576332092285]\n",
      "[Epoch 41/100] [D loss: -2.5322208404541016] [G loss: -13.171110153198242]\n",
      "[Epoch 42/100] [D loss: -2.3278822898864746] [G loss: -13.972349166870117]\n",
      "[Epoch 43/100] [D loss: -2.678110361099243] [G loss: -12.51600170135498]\n",
      "[Epoch 44/100] [D loss: -2.221928358078003] [G loss: -12.55136775970459]\n",
      "[Epoch 45/100] [D loss: -2.064859390258789] [G loss: -11.777627944946289]\n",
      "[Epoch 46/100] [D loss: -1.9363956451416016] [G loss: -11.766395568847656]\n",
      "[Epoch 47/100] [D loss: -2.1526620388031006] [G loss: -11.213020324707031]\n",
      "[Epoch 48/100] [D loss: -1.9190399646759033] [G loss: -11.159011840820312]\n",
      "[Epoch 49/100] [D loss: -2.028075933456421] [G loss: -12.30850601196289]\n",
      "[Epoch 50/100] [D loss: -1.7532600164413452] [G loss: -10.56834888458252]\n",
      "[Epoch 51/100] [D loss: -1.6561477184295654] [G loss: -10.473321914672852]\n",
      "[Epoch 52/100] [D loss: -1.6071553230285645] [G loss: -9.932958602905273]\n",
      "[Epoch 53/100] [D loss: -1.5961811542510986] [G loss: -9.689038276672363]\n",
      "[Epoch 54/100] [D loss: -1.3870813846588135] [G loss: -9.28328800201416]\n",
      "[Epoch 55/100] [D loss: -1.3639914989471436] [G loss: -8.78115177154541]\n",
      "[Epoch 56/100] [D loss: -1.404484748840332] [G loss: -8.846993446350098]\n",
      "[Epoch 57/100] [D loss: -1.283219814300537] [G loss: -9.14635181427002]\n",
      "[Epoch 58/100] [D loss: -1.2434059381484985] [G loss: -8.640236854553223]\n",
      "[Epoch 59/100] [D loss: -1.1745049953460693] [G loss: -8.560070991516113]\n",
      "[Epoch 60/100] [D loss: -1.1812598705291748] [G loss: -7.558991432189941]\n",
      "[Epoch 61/100] [D loss: -1.1462985277175903] [G loss: -8.0425386428833]\n",
      "[Epoch 62/100] [D loss: -1.2035727500915527] [G loss: -7.96445369720459]\n",
      "[Epoch 63/100] [D loss: -0.9854608178138733] [G loss: -8.125322341918945]\n",
      "[Epoch 64/100] [D loss: -1.1266705989837646] [G loss: -7.192074298858643]\n",
      "[Epoch 65/100] [D loss: -1.1650484800338745] [G loss: -7.569380283355713]\n",
      "[Epoch 66/100] [D loss: -0.9161881804466248] [G loss: -7.237184524536133]\n",
      "[Epoch 67/100] [D loss: -0.9432037472724915] [G loss: -6.993933200836182]\n",
      "[Epoch 68/100] [D loss: -1.0298677682876587] [G loss: -7.325349807739258]\n",
      "[Epoch 69/100] [D loss: -0.8455012440681458] [G loss: -6.765603065490723]\n",
      "[Epoch 70/100] [D loss: -0.8791732788085938] [G loss: -6.396880149841309]\n",
      "[Epoch 71/100] [D loss: -0.9190502166748047] [G loss: -6.734687805175781]\n",
      "[Epoch 72/100] [D loss: -0.9454110860824585] [G loss: -6.376499176025391]\n",
      "[Epoch 73/100] [D loss: -0.8021875619888306] [G loss: -6.142312526702881]\n",
      "[Epoch 74/100] [D loss: -0.7777722477912903] [G loss: -5.857353210449219]\n",
      "[Epoch 75/100] [D loss: -0.7818695902824402] [G loss: -6.674740314483643]\n",
      "[Epoch 76/100] [D loss: -0.7890409231185913] [G loss: -6.272414207458496]\n",
      "[Epoch 77/100] [D loss: -0.730279803276062] [G loss: -5.777403354644775]\n",
      "[Epoch 78/100] [D loss: -0.7033067941665649] [G loss: -5.864871501922607]\n",
      "[Epoch 79/100] [D loss: -0.7406947016716003] [G loss: -5.9116530418396]\n",
      "[Epoch 80/100] [D loss: -0.6918365359306335] [G loss: -5.937277317047119]\n",
      "[Epoch 81/100] [D loss: -0.6683916449546814] [G loss: -4.955435752868652]\n",
      "[Epoch 82/100] [D loss: -0.6450240015983582] [G loss: -5.433443546295166]\n",
      "[Epoch 83/100] [D loss: -0.702489972114563] [G loss: -5.316287517547607]\n",
      "[Epoch 84/100] [D loss: -0.7197603583335876] [G loss: -5.329766273498535]\n",
      "[Epoch 85/100] [D loss: -0.7755527496337891] [G loss: -5.368108749389648]\n",
      "[Epoch 86/100] [D loss: -0.6982875466346741] [G loss: -4.2589006423950195]\n",
      "[Epoch 87/100] [D loss: -0.6282730102539062] [G loss: -4.970733642578125]\n",
      "[Epoch 88/100] [D loss: -0.6553910970687866] [G loss: -4.773502826690674]\n",
      "[Epoch 89/100] [D loss: -0.7771084308624268] [G loss: -3.6404809951782227]\n",
      "[Epoch 90/100] [D loss: -0.6616150736808777] [G loss: -4.321203708648682]\n",
      "[Epoch 91/100] [D loss: -0.6416692137718201] [G loss: -4.253824234008789]\n",
      "[Epoch 92/100] [D loss: -0.6513965725898743] [G loss: -4.304967403411865]\n",
      "[Epoch 93/100] [D loss: -0.6924518942832947] [G loss: -3.868760824203491]\n",
      "[Epoch 94/100] [D loss: -0.6274276375770569] [G loss: -3.4864699840545654]\n",
      "[Epoch 95/100] [D loss: -0.6458284854888916] [G loss: -3.5545670986175537]\n",
      "[Epoch 96/100] [D loss: -0.6129956841468811] [G loss: -3.871629476547241]\n",
      "[Epoch 97/100] [D loss: -0.7812764644622803] [G loss: -2.5567562580108643]\n",
      "[Epoch 98/100] [D loss: -0.5511329770088196] [G loss: -3.3424301147460938]\n",
      "[Epoch 99/100] [D loss: -0.537727415561676] [G loss: -3.7656936645507812]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:25:19.330323Z",
     "start_time": "2024-08-28T15:25:19.324509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_balanced_fake_data(generator, X, y):\n",
    "    # Calculate the number of samples for each class in the original dataset\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    max_samples = max(class_counts)\n",
    "\n",
    "    X_all_fake = []\n",
    "    y_all_fake = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Calculate the number of samples needed to balance the class\n",
    "        samples_needed = max_samples - class_counts[cls]\n",
    "        \n",
    "        if samples_needed > 0:\n",
    "            noise = torch.randn(samples_needed, 144, 1).to('cpu')\n",
    "            labels = torch.tensor(np.full(samples_needed, cls)).long().to('cpu')\n",
    "            generator.to('cpu')\n",
    "            X_fakes = generator(noise, labels)\n",
    "            X_all_fake.append(X_fakes.detach().numpy())\n",
    "            y_all_fake.append(np.full(samples_needed, cls))\n",
    "\n",
    "    # Concatenate the original data with the generated fake data\n",
    "    X_all_fake = np.concatenate(X_all_fake, axis=0)\n",
    "    y_all_fake = np.concatenate(y_all_fake, axis=0)\n",
    "\n",
    "    X_augmented = np.concatenate((X, X_all_fake), axis=0)\n",
    "    y_augmented = np.concatenate((y, y_all_fake), axis=0)\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def increase_dataset_with_augmented_data(generator, X, y, increase_ratio=0.4):\n",
    "    # Get the augmented data\n",
    "    X_augmented, y_augmented = get_balanced_fake_data(generator, X, y)\n",
    "    samples_needed = int(0.4 * X_augmented.shape[0] /2)\n",
    "    X_all_fake_zeros = []\n",
    "    y_all_fake_zeros = []\n",
    "    X_all_fake_ones = []\n",
    "    y_all_fake_ones = []\n",
    "    if samples_needed > 0:\n",
    "            noise = torch.randn(samples_needed, 144, 1).to('cpu')\n",
    "            labels = torch.tensor(np.full(samples_needed, 0)).long().to('cpu')\n",
    "            generator.to('cpu')\n",
    "            X_fakes = generator(noise, labels)\n",
    "            X_all_fake_zeros.append(X_fakes.detach().numpy())\n",
    "            y_all_fake_zeros.append(np.full(samples_needed, 0))\n",
    "    if samples_needed > 0:\n",
    "            noise = torch.randn(samples_needed, 144, 1).to('cpu')\n",
    "            labels = torch.tensor(np.full(samples_needed, 1)).long().to('cpu')\n",
    "            generator.to('cpu')\n",
    "            X_fakes = generator(noise, labels)\n",
    "            X_all_fake_ones.append(X_fakes.detach().numpy())\n",
    "            y_all_fake_ones.append(np.full(samples_needed, 1))\n",
    "    # Concatenate the original data with the selected augmented data\n",
    "    X_all_fake_ones = np.array(X_all_fake_ones).squeeze(0)\n",
    "    X_all_fake_zeros = np.array(X_all_fake_zeros).squeeze(0)\n",
    "    y_all_fake_zeros = np.array(y_all_fake_zeros).squeeze(0)\n",
    "    y_all_fake_ones = np.array(y_all_fake_ones).squeeze(0)\n",
    "    X_new = np.concatenate((X_augmented, X_all_fake_zeros, X_all_fake_ones), axis=0)\n",
    "    y_new = np.concatenate((y_augmented, y_all_fake_zeros, y_all_fake_ones), axis=0)\n",
    "    \n",
    "    return X_new, y_new"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:39:47.110172Z",
     "start_time": "2024-08-28T10:39:47.033698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the number of samples for each type\n",
    "sizes = [X_Blue.shape[0], X_Galben.shape[0], X_mov.shape[0], X_Verde.shape[0]]\n",
    "labels = ['Blue', 'Galben', 'Mov', 'Verde']\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8)) \n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Data Distribution by Color')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:20:58.853167Z",
     "start_time": "2024-08-27T15:20:58.850192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Make a dictionary for the colors and the concatenated data\n",
    "data_dict = {\n",
    "    'Blue': (X_Blue, y_Blue),\n",
    "    'Galben': (X_Galben, y_Galben),\n",
    "    'Mov': (X_mov, y_mov),\n",
    "    'Verde': (X_Verde, y_Verde),\n",
    "    \"All\" : (X_all, y_all)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:21:00.592510Z",
     "start_time": "2024-08-27T15:20:59.717508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shallow_NN = shallow_nn_models(data_dict)\n",
    "metrics = shallow_NN.train_model(shallow_NN.train_knn)\n",
    "print(metrics)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cpu_count() got an unexpected keyword argument 'only_physical_cores'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m_openmp_helpers.pyx:66\u001B[0m, in \u001B[0;36msklearn.utils._openmp_helpers._openmp_effective_n_threads\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m shallow_NN \u001B[38;5;241m=\u001B[39m shallow_nn_models(data_dict)\n\u001B[0;32m----> 2\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[43mshallow_NN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshallow_NN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_knn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(metrics)\n",
      "File \u001B[0;32m~/EEG/BCI_award/Ai-training/shallow_nn_model_class.py:38\u001B[0m, in \u001B[0;36mshallow_nn_models.train_model\u001B[0;34m(self, model_training_function)\u001B[0m\n\u001B[1;32m     35\u001B[0m model \u001B[38;5;241m=\u001B[39m model_training_function(X_train, y_train)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Predict on the test data\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[1;32m     41\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred)\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:259\u001B[0m, in \u001B[0;36mKNeighborsClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbrute\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m ArgKminClassMode\u001B[38;5;241m.\u001B[39mis_usable_for(\n\u001B[1;32m    257\u001B[0m         X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric\n\u001B[1;32m    258\u001B[0m     ):\n\u001B[0;32m--> 259\u001B[0m         probabilities \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs_2d_:\n\u001B[1;32m    261\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mstack(\n\u001B[1;32m    262\u001B[0m                 [\n\u001B[1;32m    263\u001B[0m                     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_[idx][np\u001B[38;5;241m.\u001B[39margmax(probas, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)]\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    266\u001B[0m                 axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    267\u001B[0m             )\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:366\u001B[0m, in \u001B[0;36mKNeighborsClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m probabilities\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;66;03m# In that case, we do not need the distances to perform\u001B[39;00m\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;66;03m# the weighting so we do not compute them.\u001B[39;00m\n\u001B[0;32m--> 366\u001B[0m     neigh_ind \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    367\u001B[0m     neigh_dist \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/sklearn/neighbors/_base.py:849\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[0;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[1;32m    842\u001B[0m use_pairwise_distances_reductions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    843\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbrute\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m ArgKmin\u001B[38;5;241m.\u001B[39mis_usable_for(\n\u001B[1;32m    845\u001B[0m         X \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meffective_metric_\n\u001B[1;32m    846\u001B[0m     )\n\u001B[1;32m    847\u001B[0m )\n\u001B[1;32m    848\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_pairwise_distances_reductions:\n\u001B[0;32m--> 849\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mArgKmin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_X\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_neighbors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffective_metric_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffective_metric_params_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbrute\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecomputed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m issparse(X)\n\u001B[1;32m    861\u001B[0m ):\n\u001B[1;32m    862\u001B[0m     results \u001B[38;5;241m=\u001B[39m _kneighbors_from_graph(\n\u001B[1;32m    863\u001B[0m         X, n_neighbors\u001B[38;5;241m=\u001B[39mn_neighbors, return_distance\u001B[38;5;241m=\u001B[39mreturn_distance\n\u001B[1;32m    864\u001B[0m     )\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:278\u001B[0m, in \u001B[0;36mArgKmin.compute\u001B[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \n\u001B[1;32m    199\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03mreturns.\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m Y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat64:\n\u001B[0;32m--> 278\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mArgKmin64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m Y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32:\n\u001B[1;32m    290\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ArgKmin32\u001B[38;5;241m.\u001B[39mcompute(\n\u001B[1;32m    291\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m    292\u001B[0m         Y\u001B[38;5;241m=\u001B[39mY,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    298\u001B[0m         return_distance\u001B[38;5;241m=\u001B[39mreturn_distance,\n\u001B[1;32m    299\u001B[0m     )\n",
      "File \u001B[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:59\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:77\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:338\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.EuclideanArgKmin64.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:108\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msklearn/metrics/_pairwise_distances_reduction/_base.pyx:144\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._base.BaseDistancesReduction64.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_openmp_helpers.pyx:21\u001B[0m, in \u001B[0;36msklearn.utils._openmp_helpers._openmp_effective_n_threads\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_openmp_helpers.pyx:68\u001B[0m, in \u001B[0;36msklearn.utils._openmp_helpers._openmp_effective_n_threads\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: cpu_count() got an unexpected keyword argument 'only_physical_cores'"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:46:36.956679Z",
     "start_time": "2024-08-28T07:46:36.921640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train_MLP(X_train, y_train):\n",
    "    # Initialize the MLP classifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "    \n",
    "    # Fit the classifier on the training data\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    # Return the trained model\n",
    "    return mlp"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:21:29.203118Z",
     "start_time": "2024-08-27T15:21:03.687572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_MLP = shallow_NN.train_model(train_MLP)\n",
    "print(metrics_MLP)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.5454545454545454}, 'Galben': {'accuracy': 0.5811965811965812}, 'Mov': {'accuracy': 0.6515151515151515}, 'Verde': {'accuracy': 0.635593220338983}, 'All': {'accuracy': 0.606516290726817}}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:48:49.975669Z",
     "start_time": "2024-08-28T07:48:49.973751Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.ensemble import RandomForestClassifier\n",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:48:50.610437Z",
     "start_time": "2024-08-28T07:48:50.608241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_RandomForest(X_train, y_train):\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            \n",
    "            # Fit the classifier on the training data\n",
    "    rf.fit(X_train, y_train)\n",
    "            \n",
    "            # Return the trained model\n",
    "    return rf"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:39:57.486394Z",
     "start_time": "2024-08-27T15:39:36.762601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_RF = shallow_NN.train_model(train_RandomForest)\n",
    "print(metrics_RF)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.7171717171717171}, 'Galben': {'accuracy': 0.7948717948717948}, 'Mov': {'accuracy': 0.9090909090909091}, 'Verde': {'accuracy': 0.940677966101695}, 'All': {'accuracy': 0.7192982456140351}}\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:46:40.377027Z",
     "start_time": "2024-08-28T07:46:40.231712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_GradientBoosting(X_train, y_train):\n",
    "    # Initialize the Gradient Boosting classifier\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the classifier on the training data\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "    # Return the trained model\n",
    "    return gb"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:11:17.549831Z",
     "start_time": "2024-08-22T10:51:38.489767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_GB = shallow_NN.train_model(train_GradientBoosting)\n",
    "print(metrics_GB)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.7676767676767676}, 'Galben': {'accuracy': 0.7863247863247863}, 'Mov': {'accuracy': 0.8939393939393939}, 'Verde': {'accuracy': 0.8898305084745762}, 'All': {'accuracy': 0.7092731829573935}}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T19:03:58.411339Z",
     "start_time": "2024-08-27T19:03:58.408768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_GradientBoostingTrees(X_train, y_train):\n",
    "    # Initialize the Gradient Boosting Trees classifier\n",
    "    gbt = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the classifier on the training data\n",
    "    gbt.fit(X_train, y_train)\n",
    "\n",
    "    # Return the trained model\n",
    "    return gbt"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:42:53.887774Z",
     "start_time": "2024-08-22T11:22:46.262222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_GBT = shallow_NN.train_model(train_GradientBoostingTrees)\n",
    "print(metrics_GBT)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.7676767676767676}, 'Galben': {'accuracy': 0.7863247863247863}, 'Mov': {'accuracy': 0.8939393939393939}, 'Verde': {'accuracy': 0.8898305084745762}, 'All': {'accuracy': 0.7092731829573935}}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T19:04:01.873007Z",
     "start_time": "2024-08-27T19:04:01.870292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_accuracy_diff(metrics_dict):\n",
    "    differences = []\n",
    "    all_accuracy = metrics_dict['All']['accuracy']\n",
    "    \n",
    "    for key, value in metrics_dict.items():\n",
    "        if key != 'All':\n",
    "            diff = ( value['accuracy'] - all_accuracy) * 100\n",
    "            differences.append(diff)\n",
    "    \n",
    "    mean_diff = np.mean(differences)\n",
    "    return mean_diff"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:47:03.232277Z",
     "start_time": "2024-08-22T11:47:03.229651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_diff = calculate_accuracy_diff(metrics)\n",
    "print(mean_diff)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.797685068425482\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:47:09.416415Z",
     "start_time": "2024-08-22T11:47:09.413018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_diff_MLP = calculate_accuracy_diff(metrics_MLP)\n",
    "print(mean_diff_MLP)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3076416100501713\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:47:28.236648Z",
     "start_time": "2024-08-22T11:47:28.234343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_diff_RF = calculate_accuracy_diff(metrics_RF)\n",
    "print(mean_diff_RF)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.11548511949939\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:47:33.110470Z",
     "start_time": "2024-08-22T11:47:33.107503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_diff_GB = calculate_accuracy_diff(metrics_GB)\n",
    "print(mean_diff_GB)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.516968114648753\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:47:38.602029Z",
     "start_time": "2024-08-22T11:47:38.598850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_diff_GBT = calculate_accuracy_diff(metrics_GBT)\n",
    "print(mean_diff_GBT)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.516968114648753\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:47:54.306383Z",
     "start_time": "2024-08-22T11:47:54.303715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Make mean of mean_diffs\n",
    "mean_of_mean_diffs = np.mean([mean_diff, mean_diff_MLP, mean_diff_RF, mean_diff_GB, mean_diff_GBT])\n",
    "print(mean_of_mean_diffs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.527892961434443\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:29:29.716756Z",
     "start_time": "2024-08-28T07:29:29.713713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_data(yus):\n",
    "    zeros = 0\n",
    "    ones = 0\n",
    "    for i in range(len(yus)):\n",
    "        if yus[i] == 0:\n",
    "            zeros += 1\n",
    "        else:\n",
    "            ones += 1\n",
    "    print(f\"Number of zeros: {zeros}\")  \n",
    "    print(f\"Number of ones: {ones}\")"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:25:29.528423Z",
     "start_time": "2024-08-28T15:25:29.456310Z"
    }
   },
   "cell_type": "code",
   "source": "XBLue_augmented,yBlue_augmented = increase_dataset_with_augmented_data(Blue_generator,X_Blue, y_Blue)",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Blue_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m XBLue_augmented,yBlue_augmented \u001B[38;5;241m=\u001B[39m increase_dataset_with_augmented_data(\u001B[43mBlue_generator\u001B[49m,X_Blue, y_Blue)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Blue_generator' is not defined"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:29:33.829771Z",
     "start_time": "2024-08-28T07:29:33.826618Z"
    }
   },
   "cell_type": "code",
   "source": "XBLue_augmented.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 16, 1000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:29:42.826979Z",
     "start_time": "2024-08-28T07:29:42.563914Z"
    }
   },
   "cell_type": "code",
   "source": "XYellow_augmented,yYellow_augmented = increase_dataset_with_augmented_data(galbel_generator,X_Galben, y_Galben)",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:29:58.170931Z",
     "start_time": "2024-08-28T07:29:58.167777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(XYellow_augmented.shape)\n",
    "print(test_data(yYellow_augmented))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(934, 16, 1000)\n",
      "Number of zeros: 467\n",
      "Number of ones: 467\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:30:22.099576Z",
     "start_time": "2024-08-28T07:30:21.853304Z"
    }
   },
   "cell_type": "code",
   "source": "Xmov_augmented,ymov_augmented = increase_dataset_with_augmented_data(mov_generator,X_mov, y_mov)",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:30:22.828507Z",
     "start_time": "2024-08-28T07:30:22.825925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(Xmov_augmented.shape)\n",
    "print(test_data(ymov_augmented))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 16, 1000)\n",
      "Number of zeros: 343\n",
      "Number of ones: 343\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:30:30.392189Z",
     "start_time": "2024-08-28T07:30:29.972663Z"
    }
   },
   "cell_type": "code",
   "source": "XVerde_augmented,yVerde_augmented = increase_dataset_with_augmented_data(green_generator,X_Verde, y_Verde)",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:30:37.618558Z",
     "start_time": "2024-08-28T07:30:37.615528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(XVerde_augmented.shape)\n",
    "print(test_data(yVerde_augmented))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 16, 1000)\n",
      "Number of zeros: 460\n",
      "Number of ones: 460\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:31:13.784217Z",
     "start_time": "2024-08-28T07:31:13.660700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "XAll_augmented = np.concatenate((XBLue_augmented, XYellow_augmented, Xmov_augmented, XVerde_augmented), axis=0)\n",
    "yAll_augmented = np.concatenate((yBlue_augmented, yYellow_augmented, ymov_augmented, yVerde_augmented), axis=0)"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:31:29.824808Z",
     "start_time": "2024-08-28T07:31:29.821373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(XAll_augmented.shape)\n",
    "print(test_data(yAll_augmented))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3464, 16, 1000)\n",
      "Number of zeros: 1732\n",
      "Number of ones: 1732\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:25:36.361503Z",
     "start_time": "2024-08-28T15:25:36.349365Z"
    }
   },
   "cell_type": "code",
   "source": "np.savez('Blue.npz', X=XBLue_augmented, y=yBlue_augmented)",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XBLue_augmented' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m np\u001B[38;5;241m.\u001B[39msavez(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBlue.npz\u001B[39m\u001B[38;5;124m'\u001B[39m, X\u001B[38;5;241m=\u001B[39m\u001B[43mXBLue_augmented\u001B[49m, y\u001B[38;5;241m=\u001B[39myBlue_augmented)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'XBLue_augmented' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:37:06.989Z",
     "start_time": "2024-08-28T07:37:06.902639Z"
    }
   },
   "cell_type": "code",
   "source": "np.savez('Mov.npz', X=Xmov_augmented, y=ymov_augmented)",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:37:50.106414Z",
     "start_time": "2024-08-28T07:37:49.993154Z"
    }
   },
   "cell_type": "code",
   "source": "np.savez('Verde.npz', X=XVerde_augmented, y=yVerde_augmented)",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:38:33.312984Z",
     "start_time": "2024-08-28T07:38:33.196102Z"
    }
   },
   "cell_type": "code",
   "source": "np.savez('Yellow.npz', X=XYellow_augmented, y=yYellow_augmented)",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:38:47.655403Z",
     "start_time": "2024-08-28T07:38:47.201910Z"
    }
   },
   "cell_type": "code",
   "source": "np.savez('All.npz', X=XAll_augmented, y=yAll_augmented)",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:28.191504Z",
     "start_time": "2024-08-28T17:55:27.465200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LOad the file All.npz\n",
    "data = np.load('All.npz')\n",
    "XAll_augmented = data['X']\n",
    "yAll_augmented = data['y']"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:29.621589Z",
     "start_time": "2024-08-28T17:55:29.478037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"Blue.npz\")\n",
    "XBLue_augmented = data['X']\n",
    "yBlue_augmented = data['y']"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:30.280980Z",
     "start_time": "2024-08-28T17:55:30.193896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"Mov.npz\")\n",
    "Xmov_augmented = data['X']\n",
    "ymov_augmented = data['y']"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:30.798786Z",
     "start_time": "2024-08-28T17:55:30.689473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"Verde.npz\")\n",
    "XVerde_augmented = data['X']\n",
    "yVerde_augmented = data['y']"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:31.467955Z",
     "start_time": "2024-08-28T17:55:31.315773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"Yellow.npz\")\n",
    "XYellow_augmented = data['X']\n",
    "yYellow_augmented = data['y']"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:31.983435Z",
     "start_time": "2024-08-28T17:55:31.980522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Make a dictionary for the colors and the concatenated data\n",
    "data_dict_fake = {\n",
    "    'Blue': (XBLue_augmented, yBlue_augmented),\n",
    "    'Galben': (XYellow_augmented, yYellow_augmented),\n",
    "    'Mov': (Xmov_augmented, ymov_augmented),\n",
    "    'Verde': (XVerde_augmented, yVerde_augmented),\n",
    "    \"All\" : (XAll_augmented, yAll_augmented)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:38:50.219571Z",
     "start_time": "2024-08-27T14:38:50.215747Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:39:06.661893Z",
     "start_time": "2024-08-27T14:39:05.090911Z"
    }
   },
   "cell_type": "code",
   "source": "Xus,yus = get_fake_data_from_generatorus(all_generator, X_all, y_all)",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:39:14.318554Z",
     "start_time": "2024-08-27T14:39:14.314557Z"
    }
   },
   "cell_type": "code",
   "source": "Xus.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3187, 16, 1000)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:46:08.329958Z",
     "start_time": "2024-08-28T07:46:05.586909Z"
    }
   },
   "cell_type": "code",
   "source": "shallow_NN_augmented = shallow_nn_models(data_dict_fake)\n",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:46:08.356513Z",
     "start_time": "2024-08-28T07:46:08.336428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = shallow_NN_augmented.train_model(shallow_NN.train_knn)\n",
    "print(metrics) "
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shallow_NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[89], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m metrics \u001B[38;5;241m=\u001B[39m shallow_NN_augmented\u001B[38;5;241m.\u001B[39mtrain_model(\u001B[43mshallow_NN\u001B[49m\u001B[38;5;241m.\u001B[39mtrain_knn)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(metrics) \n",
      "\u001B[0;31mNameError\u001B[0m: name 'shallow_NN' is not defined"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:47:39.477742Z",
     "start_time": "2024-08-28T07:47:13.526166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_MLP_augmented = shallow_NN_augmented.train_model(train_MLP)\n",
    "print(metrics_MLP_augmented)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.827027027027027}, 'Galben': {'accuracy': 0.6951871657754011}, 'Mov': {'accuracy': 0.855072463768116}, 'Verde': {'accuracy': 0.6684782608695652}, 'All': {'accuracy': 0.7561327561327561}}\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:24:16.652861Z",
     "start_time": "2024-08-27T15:24:16.650091Z"
    }
   },
   "cell_type": "code",
   "source": "print(metrics_MLP_augmented)\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.8354430379746836}, 'Galben': {'accuracy': 0.6951871657754011}, 'Mov': {'accuracy': 0.819047619047619}, 'Verde': {'accuracy': 0.6808510638297872}, 'All': {'accuracy': 0.7366771159874608}}\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:21.008216Z",
     "start_time": "2024-08-27T15:41:21.005815Z"
    }
   },
   "cell_type": "code",
   "source": "print(metrics_RF)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.7171717171717171}, 'Galben': {'accuracy': 0.7948717948717948}, 'Mov': {'accuracy': 0.9090909090909091}, 'Verde': {'accuracy': 0.940677966101695}, 'All': {'accuracy': 0.7192982456140351}}\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:49:32.079478Z",
     "start_time": "2024-08-28T07:48:56.145692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_RF_augmented = shallow_NN_augmented.train_model(train_RandomForest)\n",
    "print(metrics_RF_augmented)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': {'accuracy': 0.8432432432432433}, 'Galben': {'accuracy': 0.8502673796791443}, 'Mov': {'accuracy': 0.8623188405797102}, 'Verde': {'accuracy': 0.8206521739130435}, 'All': {'accuracy': 0.7546897546897547}}\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:38.342317Z",
     "start_time": "2024-08-28T17:55:38.339638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "fs= 250                  #sampling frequency\n",
    "channel= 16              #number of electrode\n",
    "num_input= 1             #number of channel picture (for EEG signal is always : 1)\n",
    "num_class= 1             #number of classes \n",
    "signal_length = 1000      #number of sample in each tarial\n",
    "\n",
    "F1= 8                    #number of temporal filters\n",
    "D= 3                     #depth multiplier (number of spatial filters)\n",
    "F2= D*F1                 #number of pointwise filters"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:38.959678Z",
     "start_time": "2024-08-28T17:55:38.955599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device= 'cuda'\n",
    "kernel_size_1= (1,round(fs/2)) \n",
    "kernel_size_2= (channel, 1)\n",
    "kernel_size_3= (1, round(fs/8))\n",
    "kernel_size_4= (1, 1)\n",
    "\n",
    "kernel_avgpool_1= (1,4)\n",
    "kernel_avgpool_2= (1,8)\n",
    "dropout_rate= 0.2\n",
    "\n",
    "ks0= int(round((kernel_size_1[0]-1)/2))\n",
    "ks1= int(round((kernel_size_1[1]-1)/2))\n",
    "kernel_padding_1= (ks0, ks1-1)\n",
    "ks0= int(round((kernel_size_3[0]-1)/2))\n",
    "ks1= int(round((kernel_size_3[1]-1)/2))\n",
    "kernel_padding_3= (ks0, ks1)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:40.114750Z",
     "start_time": "2024-08-28T17:55:40.109848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # layer 1\n",
    "        self.conv2d = nn.Conv2d(num_input, F1, kernel_size_1, padding=kernel_padding_1)\n",
    "        self.Batch_normalization_1 = nn.BatchNorm2d(F1)\n",
    "        # layer 2\n",
    "        self.Depthwise_conv2D = nn.Conv2d(F1, D*F1, kernel_size_2, groups= F1)\n",
    "        self.Batch_normalization_2 = nn.BatchNorm2d(D*F1)\n",
    "        self.Elu = nn.ELU()\n",
    "        self.Average_pooling2D_1 = nn.AvgPool2d(kernel_avgpool_1)\n",
    "        self.Dropout = nn.Dropout2d(dropout_rate)\n",
    "        # layer 3\n",
    "        self.Separable_conv2D_depth = nn.Conv2d(D*F1, D*F1, kernel_size_3, padding=kernel_padding_3, groups= D*F1)\n",
    "        self.Separable_conv2D_point = nn.Conv2d(D*F1, F2, kernel_size_4)\n",
    "        self.Batch_normalization_3 = nn.BatchNorm2d(F2)\n",
    "        self.Average_pooling2D_2 = nn.AvgPool2d(kernel_avgpool_2)\n",
    "        # layer 4\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.LSTM = nn.LSTM(input_size=F2*round(signal_length/32), hidden_size=128, batch_first=True)\n",
    "        self.Dense = nn.Linear(128, num_class)\n",
    "        self.Softmax = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # layer 1\n",
    "        y = self.Batch_normalization_1(self.conv2d(x))\n",
    "        # layer 2\n",
    "        y = self.Batch_normalization_2(self.Depthwise_conv2D(y))\n",
    "        y = self.Elu(y)\n",
    "        y = self.Dropout(self.Average_pooling2D_1(y))\n",
    "        # layer 3\n",
    "        y = self.Separable_conv2D_depth(y)\n",
    "        y = self.Batch_normalization_3(self.Separable_conv2D_point(y))\n",
    "        y = self.Elu(y)\n",
    "        y = self.Dropout(self.Average_pooling2D_2(y))\n",
    "        # layer 4\n",
    "        y = self.Flatten(y)\n",
    "        y = y.unsqueeze(1)  # Add sequence dimension for LSTM\n",
    "        y, _ = self.LSTM(y)\n",
    "        y = y[:, -1, :]  # Take the last output of the LSTM\n",
    "        y = self.Dense(y)\n",
    "        y = self.Softmax(y)\n",
    "        \n",
    "        return y"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T19:45:55.470859Z",
     "start_time": "2024-08-27T19:45:54.062588Z"
    }
   },
   "cell_type": "code",
   "source": "X_all_augmented, y_all_augmented =get_fake_data_from_generatorus(all_generator,X_all,y_all)",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T19:45:55.528909Z",
     "start_time": "2024-08-27T19:45:55.526094Z"
    }
   },
   "cell_type": "code",
   "source": "X_all_augmented.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3187, 16, 1000)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T19:45:56.342997Z",
     "start_time": "2024-08-27T19:45:56.340480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Could you squexx from X_all_augmented the shape from (16,1000) to (16000,1)\n",
    "X_all_augmented = X_all_augmented.reshape(3187, 16000)"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T19:45:57.050798Z",
     "start_time": "2024-08-27T19:45:57.047123Z"
    }
   },
   "cell_type": "code",
   "source": "X_all_augmented.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3187, 16000)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:24:56.777149Z",
     "start_time": "2024-08-28T10:24:56.774150Z"
    }
   },
   "cell_type": "code",
   "source": "XYellow_augmented.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 16, 1000)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:49.051739Z",
     "start_time": "2024-08-28T17:55:48.921600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "XVerde_augmented_reshaped = XAll_augmented.reshape(XAll_augmented.shape[0],  16000)\n",
    "# Convert data to tensors\n",
    "signal = torch.tensor(XVerde_augmented_reshaped)\n",
    "label = torch.tensor(yAll_augmented)\n",
    "print(signal.shape)\n",
    "# Define batch size\n",
    "train_batch_size = 64\n",
    "\n",
    "# Define the split ratio\n",
    "train_size = int(0.8 * len(signal))\n",
    "test_size = len(signal) - train_size\n",
    "\n",
    "# Split the signal and label into training and testing sets\n",
    "# Shuffle the data before splitting\n",
    "indices = torch.randperm(signal.size(0))\n",
    "shuffled_signal = signal[indices]\n",
    "shuffled_label = label[indices]\n",
    "\n",
    "# Split the shuffled data\n",
    "train_signal, test_signal = torch.split(shuffled_signal, [train_size, test_size])\n",
    "train_label, test_label = torch.split(shuffled_label, [train_size, test_size])\n",
    "# Create TensorDatasets for training and testing sets\n",
    "train_dataset = TensorDataset(train_signal, train_label)\n",
    "test_dataset = TensorDataset(test_signal, test_label)\n",
    "\n",
    "# Create DataLoaders for training and testing sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# Print the shape of the transformed signal\n",
    "for data in train_loader:\n",
    "    print(data[0].shape)\n",
    "    break\n",
    "\n",
    "for data in test_loader:\n",
    "    print(data[0].shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3464, 16000])\n",
      "torch.Size([64, 16000])\n",
      "torch.Size([64, 16000])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:49.897621Z",
     "start_time": "2024-08-28T17:55:49.894980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(signal, label)\n",
    "data_loader = DataLoader(dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# Correct print statement\n",
    "print(\"train batch size:\", train_loader.batch_size, \", num of batch:\", len(train_loader))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batch size: 64 , num of batch: 44\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:51.083087Z",
     "start_time": "2024-08-28T17:55:51.080196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:52.058719Z",
     "start_time": "2024-08-28T17:55:51.960845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    loss_train = AverageMeter()\n",
    "    acc_train = Accuracy(task='binary').to(device)\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        inputs = inputs.float().to(device)\n",
    "        model = model.to(device)\n",
    "        #Iterate through inputs\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(1).float()\n",
    "        targets = targets.float()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_train.update(loss.item())\n",
    "        acc_train(outputs, targets.int())\n",
    "        \n",
    "    return model, loss_train.avg, acc_train.compute().item()"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:54.791367Z",
     "start_time": "2024-08-28T17:55:52.613913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "model = EEGNet()\n",
    "\n",
    "num_epochs = 15\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.NAdam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_train_hist = []\n",
    "acc_train_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "        model, loss_train, acc_train = train_one_epoch(model, train_loader, loss_fn, optimizer)\n",
    "        pbar.set_postfix({'Loss': f'{loss_train:.4f}', 'Accuracy': f'{acc_train*100:.2f}%'})\n",
    "        pbar.update()\n",
    "\n",
    "    loss_train_hist.append(loss_train)\n",
    "    acc_train_hist.append(acc_train)\n",
    "\n",
    "    if (epoch % 10 == 5) or (epoch % 10 == 0):\n",
    "        print(f'epoch {epoch}:')\n",
    "        print(f' Loss= {loss_train:.4}, Accuracy= {int(acc_train*100)}% \\n')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:   0%|          | 0/44 [00:01<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 16000]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m---> 14\u001B[0m         model, loss_train, acc_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m         pbar\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_train\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc_train\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m})\n\u001B[1;32m     16\u001B[0m         pbar\u001B[38;5;241m.\u001B[39mupdate()\n",
      "Cell \u001B[0;32mIn[26], line 15\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[0;34m(model, train_loader, loss_fn, optimizer)\u001B[0m\n\u001B[1;32m     13\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#Iterate through inputs\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m outputs \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     17\u001B[0m targets \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[22], line 28\u001B[0m, in \u001B[0;36mEEGNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# layer 1\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mBatch_normalization_1(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;66;03m# layer 2\u001B[39;00m\n\u001B[1;32m     30\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mBatch_normalization_2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDepthwise_conv2D(y))\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    452\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    453\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 16000]"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:47:10.402685Z",
     "start_time": "2024-08-28T10:47:10.337342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, data_loader, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in data_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.float().to(device).unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1).float()\n",
    "            print(outputs)\n",
    "\n",
    "            targets = targets.float()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Assuming binary classification\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Example usage:\n",
    "test_loss, test_accuracy = test_model(model, test_loader, loss_fn, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy*100:.2f}%')"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 1, 1, 125], expected input[1, 64, 1, 16000] to have 1 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 31\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m avg_loss, accuracy\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Example usage:\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m test_loss, test_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtest_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_accuracy\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[38], line 12\u001B[0m, in \u001B[0;36mtest_model\u001B[0;34m(model, data_loader, loss_fn, device)\u001B[0m\n\u001B[1;32m     10\u001B[0m inputs, targets \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     11\u001B[0m inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m outputs \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(outputs)\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[23], line 28\u001B[0m, in \u001B[0;36mEEGNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# layer 1\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mBatch_normalization_1(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;66;03m# layer 2\u001B[39;00m\n\u001B[1;32m     30\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mBatch_normalization_2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDepthwise_conv2D(y))\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/David_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    452\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    453\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=1, weight of size [8, 1, 1, 125], expected input[1, 64, 1, 16000] to have 1 channels, but got 64 channels instead"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:57.536783Z",
     "start_time": "2024-08-28T17:55:57.533939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T17:55:58.279539Z",
     "start_time": "2024-08-28T17:55:58.272275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CombinedEEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedEEGNet, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=1000, hidden_size=125, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=125, hidden_size=50, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=50, hidden_size=75, batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(input_size=75, hidden_size=125, batch_first=True)\n",
    "        self.lstm_activation = nn.Tanh()\n",
    "        self.upsample1 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(16)\n",
    "        self.relu_layer1 = nn.ReLU()\n",
    "        self.resblock1 = ResidualBlock(16)\n",
    "        self.upsample2 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(16)\n",
    "        self.relu_layer2 = nn.ReLU()\n",
    "        self.resblock2 = ResidualBlock(16)\n",
    "        self.upsample3 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(16)\n",
    "        self.relu_layer3 = nn.ReLU()\n",
    "        self.resblock3 = ResidualBlock(16)\n",
    "        self.upsample4 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(16)\n",
    "        self.relu_layer4 = nn.ReLU()\n",
    "        self.resblock4 = ResidualBlock(16)\n",
    "        self.downsample1 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.downsample_activation = nn.ReLU()\n",
    "        \n",
    "        # Adding 30 more convolutional layers\n",
    "        self.extra_convs = nn.ModuleList([nn.Conv1d(16, 16, kernel_size=3, padding=1) for _ in range(30)])\n",
    "        self.extra_bns = nn.ModuleList([nn.BatchNorm1d(16) for _ in range(30)])\n",
    "        self.extra_relus = nn.ModuleList([nn.ReLU() for _ in range(30)])\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(16000, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 16, 1000)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu_layer1(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu_layer2(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.upsample3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu_layer3(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.upsample4(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.relu_layer4(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.downsample1(x)\n",
    "        \n",
    "        # Forward pass through the additional convolutional layers\n",
    "        for conv, bn, relu in zip(self.extra_convs, self.extra_bns, self.extra_relus):\n",
    "            x = conv(x)\n",
    "            x = bn(x)\n",
    "            x = relu(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:18:45.386318Z",
     "start_time": "2024-08-28T18:15:39.885263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "model = CombinedEEGNet()\n",
    "\n",
    "num_epochs = 100\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "optimizer = optim.NAdam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_train_hist = []\n",
    "acc_train_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "        model, loss_train, acc_train = train_one_epoch(model, train_loader, loss_fn, optimizer)\n",
    "        pbar.set_postfix({'Loss': f'{loss_train:.4f}', 'Accuracy': f'{acc_train*100:.2f}%'})\n",
    "        pbar.update()\n",
    "\n",
    "    loss_train_hist.append(loss_train)\n",
    "    acc_train_hist.append(acc_train)\n",
    "\n",
    "    if (epoch % 10 == 5) or (epoch % 10 == 0):\n",
    "        print(f'epoch {epoch}:')\n",
    "        print(f' Loss= {loss_train:.4}, Accuracy= {int(acc_train*100)}% \\n')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   2%|         | 1/44 [00:01<01:23,  1.93s/batch, Loss=0.9274, Accuracy=49.98%]\n",
      "Epoch 2/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n",
      " Loss= 0.9274, Accuracy= 49% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.7366, Accuracy=50.92%]\n",
      "Epoch 3/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.7021, Accuracy=49.19%]\n",
      "Epoch 4/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.6952, Accuracy=50.88%]\n",
      "Epoch 5/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.6899, Accuracy=51.86%]\n",
      "Epoch 6/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.6820, Accuracy=56.73%]\n",
      "Epoch 7/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5:\n",
      " Loss= 0.682, Accuracy= 56% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.6128, Accuracy=63.33%]\n",
      "Epoch 8/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.5074, Accuracy=69.11%]\n",
      "Epoch 9/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4662, Accuracy=72.65%]\n",
      "Epoch 10/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4560, Accuracy=72.43%]\n",
      "Epoch 11/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4494, Accuracy=72.25%]\n",
      "Epoch 12/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10:\n",
      " Loss= 0.4494, Accuracy= 72% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4614, Accuracy=71.82%]\n",
      "Epoch 13/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4230, Accuracy=74.16%]\n",
      "Epoch 14/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4204, Accuracy=73.51%]\n",
      "Epoch 15/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4241, Accuracy=73.51%]\n",
      "Epoch 16/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4157, Accuracy=72.86%]\n",
      "Epoch 17/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15:\n",
      " Loss= 0.4157, Accuracy= 72% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4202, Accuracy=74.38%]\n",
      "Epoch 18/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4247, Accuracy=73.58%]\n",
      "Epoch 19/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4133, Accuracy=73.08%]\n",
      "Epoch 20/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4028, Accuracy=75.53%]\n",
      "Epoch 21/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4051, Accuracy=75.24%]\n",
      "Epoch 22/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20:\n",
      " Loss= 0.4051, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4082, Accuracy=74.12%]\n",
      "Epoch 23/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4008, Accuracy=75.50%]\n",
      "Epoch 24/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4037, Accuracy=72.03%]\n",
      "Epoch 25/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3982, Accuracy=75.46%]\n",
      "Epoch 26/100:   2%|         | 1/44 [00:01<01:20,  1.87s/batch, Loss=0.3956, Accuracy=75.97%]\n",
      "Epoch 27/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25:\n",
      " Loss= 0.3956, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100:   2%|         | 1/44 [00:01<01:20,  1.87s/batch, Loss=0.3958, Accuracy=75.97%]\n",
      "Epoch 28/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4015, Accuracy=75.64%]\n",
      "Epoch 29/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3971, Accuracy=75.71%]\n",
      "Epoch 30/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3967, Accuracy=75.75%]\n",
      "Epoch 31/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4004, Accuracy=75.68%]\n",
      "Epoch 32/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30:\n",
      " Loss= 0.4004, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.4121, Accuracy=75.57%]\n",
      "Epoch 33/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4106, Accuracy=75.64%]\n",
      "Epoch 34/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3952, Accuracy=75.53%]\n",
      "Epoch 35/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3971, Accuracy=76.00%]\n",
      "Epoch 36/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3980, Accuracy=75.53%]\n",
      "Epoch 37/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35:\n",
      " Loss= 0.398, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3972, Accuracy=75.35%]\n",
      "Epoch 38/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3956, Accuracy=75.97%]\n",
      "Epoch 39/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3962, Accuracy=74.99%]\n",
      "Epoch 40/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3954, Accuracy=75.75%]\n",
      "Epoch 41/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3944, Accuracy=75.97%]\n",
      "Epoch 42/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40:\n",
      " Loss= 0.3944, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3986, Accuracy=75.97%]\n",
      "Epoch 43/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4009, Accuracy=75.89%]\n",
      "Epoch 44/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3986, Accuracy=75.86%]\n",
      "Epoch 45/100:   2%|         | 1/44 [00:01<01:20,  1.87s/batch, Loss=0.3948, Accuracy=75.97%]\n",
      "Epoch 46/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3968, Accuracy=75.97%]\n",
      "Epoch 47/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45:\n",
      " Loss= 0.3968, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3944, Accuracy=75.93%]\n",
      "Epoch 48/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3989, Accuracy=75.93%]\n",
      "Epoch 49/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4073, Accuracy=75.64%]\n",
      "Epoch 50/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4025, Accuracy=75.82%]\n",
      "Epoch 51/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3957, Accuracy=75.97%]\n",
      "Epoch 52/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50:\n",
      " Loss= 0.3957, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4025, Accuracy=75.42%]\n",
      "Epoch 53/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3970, Accuracy=75.97%]\n",
      "Epoch 54/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3960, Accuracy=75.97%]\n",
      "Epoch 55/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3948, Accuracy=75.97%]\n",
      "Epoch 56/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3956, Accuracy=75.97%]\n",
      "Epoch 57/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55:\n",
      " Loss= 0.3956, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3943, Accuracy=75.97%]\n",
      "Epoch 58/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3968, Accuracy=75.97%]\n",
      "Epoch 59/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3918, Accuracy=75.97%]\n",
      "Epoch 60/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3968, Accuracy=75.97%]\n",
      "Epoch 61/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3948, Accuracy=75.97%]\n",
      "Epoch 62/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60:\n",
      " Loss= 0.3948, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3942, Accuracy=75.97%]\n",
      "Epoch 63/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3970, Accuracy=75.97%]\n",
      "Epoch 64/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3933, Accuracy=75.97%]\n",
      "Epoch 65/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3935, Accuracy=75.97%]\n",
      "Epoch 66/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3951, Accuracy=75.97%]\n",
      "Epoch 67/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65:\n",
      " Loss= 0.3951, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3948, Accuracy=75.97%]\n",
      "Epoch 68/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3928, Accuracy=75.97%]\n",
      "Epoch 69/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3918, Accuracy=75.97%]\n",
      "Epoch 70/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3937, Accuracy=75.97%]\n",
      "Epoch 71/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3933, Accuracy=75.97%]\n",
      "Epoch 72/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70:\n",
      " Loss= 0.3933, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3924, Accuracy=75.97%]\n",
      "Epoch 73/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3935, Accuracy=75.97%]\n",
      "Epoch 74/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3957, Accuracy=75.97%]\n",
      "Epoch 75/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3983, Accuracy=75.97%]\n",
      "Epoch 76/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3947, Accuracy=75.97%]\n",
      "Epoch 77/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75:\n",
      " Loss= 0.3947, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3941, Accuracy=75.97%]\n",
      "Epoch 78/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3929, Accuracy=75.97%]\n",
      "Epoch 79/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3941, Accuracy=75.97%]\n",
      "Epoch 80/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3942, Accuracy=75.97%]\n",
      "Epoch 81/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3951, Accuracy=75.97%]\n",
      "Epoch 82/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80:\n",
      " Loss= 0.3951, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3954, Accuracy=75.97%]\n",
      "Epoch 83/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3948, Accuracy=75.97%]\n",
      "Epoch 84/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3933, Accuracy=75.97%]\n",
      "Epoch 85/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3926, Accuracy=75.97%]\n",
      "Epoch 86/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3939, Accuracy=75.97%]\n",
      "Epoch 87/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85:\n",
      " Loss= 0.3939, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3954, Accuracy=75.97%]\n",
      "Epoch 88/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3955, Accuracy=75.97%]\n",
      "Epoch 89/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3951, Accuracy=75.89%]\n",
      "Epoch 90/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.4061, Accuracy=75.93%]\n",
      "Epoch 91/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3946, Accuracy=75.97%]\n",
      "Epoch 92/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90:\n",
      " Loss= 0.3946, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3969, Accuracy=75.97%]\n",
      "Epoch 93/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3965, Accuracy=75.97%]\n",
      "Epoch 94/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3966, Accuracy=75.86%]\n",
      "Epoch 95/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3941, Accuracy=75.97%]\n",
      "Epoch 96/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3924, Accuracy=75.97%]\n",
      "Epoch 97/100:   0%|          | 0/44 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95:\n",
      " Loss= 0.3924, Accuracy= 75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100:   2%|         | 1/44 [00:01<01:19,  1.86s/batch, Loss=0.3977, Accuracy=75.97%]\n",
      "Epoch 98/100:   2%|         | 1/44 [00:01<01:20,  1.87s/batch, Loss=0.3923, Accuracy=75.97%]\n",
      "Epoch 99/100:   2%|         | 1/44 [00:01<01:20,  1.88s/batch, Loss=0.3938, Accuracy=75.97%]\n",
      "Epoch 100/100:   2%|         | 1/44 [00:01<01:19,  1.85s/batch, Loss=0.3932, Accuracy=75.97%]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:18:48.513578Z",
     "start_time": "2024-08-28T18:18:48.361034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, data_loader, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in data_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.float().to(device).unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1).float()\n",
    "            targets = targets.float()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Assuming binary classification\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Example usage:\n",
    "test_loss, test_accuracy = test_model(model, test_loader, loss_fn, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy*100:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4588, Test Accuracy: 73.30%\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:18:51.224259Z",
     "start_time": "2024-08-28T18:18:51.215585Z"
    }
   },
   "cell_type": "code",
   "source": "model.to('cpu')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedEEGNet(\n",
       "  (lstm1): LSTM(1000, 125, batch_first=True)\n",
       "  (lstm2): LSTM(125, 50, batch_first=True)\n",
       "  (lstm3): LSTM(50, 75, batch_first=True)\n",
       "  (lstm4): LSTM(75, 125, batch_first=True)\n",
       "  (lstm_activation): Tanh()\n",
       "  (upsample1): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
       "  (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (batch_norm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_layer1): ReLU()\n",
       "  (resblock1): ResidualBlock(\n",
       "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (upsample2): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
       "  (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (batch_norm2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_layer2): ReLU()\n",
       "  (resblock2): ResidualBlock(\n",
       "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (upsample3): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
       "  (conv3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (batch_norm3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_layer3): ReLU()\n",
       "  (resblock3): ResidualBlock(\n",
       "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (upsample4): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
       "  (conv4): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (batch_norm4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_layer4): ReLU()\n",
       "  (resblock4): ResidualBlock(\n",
       "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (downsample1): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (downsample_activation): ReLU()\n",
       "  (extra_convs): ModuleList(\n",
       "    (0-29): 30 x Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (extra_bns): ModuleList(\n",
       "    (0-29): 30 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (extra_relus): ModuleList(\n",
       "    (0-29): 30 x ReLU()\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=16000, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:19:33.238176Z",
     "start_time": "2024-08-28T18:19:33.226056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:33:53.677863Z",
     "start_time": "2024-08-28T18:33:53.645824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_2 = CombinedEEGNet()\n",
    "model_2.load_state_dict(torch.load('model.pth',weights_only=True))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:28:13.057635Z",
     "start_time": "2024-08-28T18:28:13.054760Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_2)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedEEGNet(\n",
      "  (lstm1): LSTM(1000, 125, batch_first=True)\n",
      "  (lstm2): LSTM(125, 50, batch_first=True)\n",
      "  (lstm3): LSTM(50, 75, batch_first=True)\n",
      "  (lstm4): LSTM(75, 125, batch_first=True)\n",
      "  (lstm_activation): Tanh()\n",
      "  (upsample1): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
      "  (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batch_norm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_layer1): ReLU()\n",
      "  (resblock1): ResidualBlock(\n",
      "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upsample2): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batch_norm2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_layer2): ReLU()\n",
      "  (resblock2): ResidualBlock(\n",
      "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upsample3): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batch_norm3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_layer3): ReLU()\n",
      "  (resblock3): ResidualBlock(\n",
      "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upsample4): ConvTranspose1d(16, 16, kernel_size=(2,), stride=(2,))\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batch_norm4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_layer4): ReLU()\n",
      "  (resblock4): ResidualBlock(\n",
      "    (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downsample1): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (downsample_activation): ReLU()\n",
      "  (extra_convs): ModuleList(\n",
      "    (0-29): 30 x Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      "  (extra_bns): ModuleList(\n",
      "    (0-29): 30 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (extra_relus): ModuleList(\n",
      "    (0-29): 30 x ReLU()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=16000, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T18:39:23.531206Z",
     "start_time": "2024-08-28T18:39:23.528607Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu124\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Andrei_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
